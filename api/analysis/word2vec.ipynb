{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,138 : INFO : loading projection weights from dataset/twitter/word2vec.model\n",
      "2019-03-30 22:30:24,253 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,255 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,256 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,258 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,260 : WARNING : duplicate word '716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,262 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,263 : WARNING : duplicate word '141' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,264 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,266 : WARNING : duplicate word '721' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,268 : WARNING : duplicate word '487' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,269 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,270 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,271 : WARNING : duplicate word '367' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,272 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,273 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,275 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,277 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,281 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,284 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,285 : WARNING : duplicate word '787' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,287 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,288 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,289 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,290 : WARNING : duplicate word '526' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,291 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,292 : WARNING : duplicate word '794' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,293 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,293 : WARNING : duplicate word '089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,294 : WARNING : duplicate word '484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,295 : WARNING : duplicate word '947' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,296 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,297 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,298 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,299 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,300 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,301 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,302 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,303 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,305 : WARNING : duplicate word '469' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,306 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,307 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,307 : WARNING : duplicate word '068' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,308 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,312 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,313 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,315 : WARNING : duplicate word '089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,316 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,317 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,317 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,318 : WARNING : duplicate word '006' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,319 : WARNING : duplicate word '471' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,320 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,321 : WARNING : duplicate word '6391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,322 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,323 : WARNING : duplicate word '38' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,323 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,324 : WARNING : duplicate word '966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,325 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,325 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,326 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,327 : WARNING : duplicate word '296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,328 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,329 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,330 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,330 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,331 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,332 : WARNING : duplicate word '2649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,332 : WARNING : duplicate word '908' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,333 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,334 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,334 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,335 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,336 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,337 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,338 : WARNING : duplicate word '8459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,339 : WARNING : duplicate word '795' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,340 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,343 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,344 : WARNING : duplicate word '119' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,345 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,346 : WARNING : duplicate word '562' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,348 : WARNING : duplicate word '428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,349 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,351 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,352 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,354 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,356 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,357 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,359 : WARNING : duplicate word '406' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,361 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,363 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,364 : WARNING : duplicate word '3105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,366 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,367 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,368 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,369 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,370 : WARNING : duplicate word '556' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,371 : WARNING : duplicate word '557' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,372 : WARNING : duplicate word '3055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,373 : WARNING : duplicate word '533' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,373 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,374 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,375 : WARNING : duplicate word '411' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,377 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,378 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,379 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,380 : WARNING : duplicate word '431' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,382 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,383 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,384 : WARNING : duplicate word '567' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,385 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,387 : WARNING : duplicate word '966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,389 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,390 : WARNING : duplicate word '067' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,391 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,392 : WARNING : duplicate word '617' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,393 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,396 : WARNING : duplicate word '912' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,398 : WARNING : duplicate word '89' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,399 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,400 : WARNING : duplicate word '513' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,401 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,403 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,405 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,406 : WARNING : duplicate word '5162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,407 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,408 : WARNING : duplicate word '025' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,409 : WARNING : duplicate word '407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,410 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,412 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,414 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,415 : WARNING : duplicate word '554' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,416 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,417 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,418 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,419 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,420 : WARNING : duplicate word '049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,421 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,422 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,423 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,424 : WARNING : duplicate word '197' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,425 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,426 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,427 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,428 : WARNING : duplicate word '34' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,429 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,430 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,432 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,433 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,434 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,435 : WARNING : duplicate word '263' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,437 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,438 : WARNING : duplicate word '544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,440 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,442 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,444 : WARNING : duplicate word '8441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,445 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,448 : WARNING : duplicate word '774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,449 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,450 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,451 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,452 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,454 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,455 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,457 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,458 : WARNING : duplicate word '961' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,463 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,465 : WARNING : duplicate word '209' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,466 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,467 : WARNING : duplicate word '119' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,468 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,469 : WARNING : duplicate word '898' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,470 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,471 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,473 : WARNING : duplicate word '974' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,474 : WARNING : duplicate word '863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,475 : WARNING : duplicate word '358' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,477 : WARNING : duplicate word '339' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,478 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,480 : WARNING : duplicate word '516' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,481 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,483 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,484 : WARNING : duplicate word '416' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,485 : WARNING : duplicate word '506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,487 : WARNING : duplicate word '357' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,490 : WARNING : duplicate word '975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,495 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,496 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,498 : WARNING : duplicate word '579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,500 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,502 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,503 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,505 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,506 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,508 : WARNING : duplicate word '354' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,511 : WARNING : duplicate word '705' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,513 : WARNING : duplicate word '617' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,514 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,517 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,518 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,519 : WARNING : duplicate word '092' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,520 : WARNING : duplicate word '1135' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,522 : WARNING : duplicate word '1944' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,523 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,524 : WARNING : duplicate word '979' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,533 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,534 : WARNING : duplicate word '779' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,538 : WARNING : duplicate word '685' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,543 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,544 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,545 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,547 : WARNING : duplicate word '764' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,550 : WARNING : duplicate word '6417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,551 : WARNING : duplicate word '626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,552 : WARNING : duplicate word '764' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,554 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,555 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,556 : WARNING : duplicate word '073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,557 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,558 : WARNING : duplicate word '432' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,561 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,562 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,564 : WARNING : duplicate word '8382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,566 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,575 : WARNING : duplicate word '367' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,575 : WARNING : duplicate word '818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,576 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,577 : WARNING : duplicate word '613' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,578 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,579 : WARNING : duplicate word '417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,580 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,581 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,582 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,582 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,583 : WARNING : duplicate word '2521' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,584 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,585 : WARNING : duplicate word '358' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,586 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,587 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,588 : WARNING : duplicate word '661' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,588 : WARNING : duplicate word '1322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,590 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,591 : WARNING : duplicate word '218' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,591 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,593 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,594 : WARNING : duplicate word '958' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,596 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,597 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,598 : WARNING : duplicate word '393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,602 : WARNING : duplicate word '651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,604 : WARNING : duplicate word '426' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,605 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,607 : WARNING : duplicate word '055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,608 : WARNING : duplicate word '461' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,610 : WARNING : duplicate word '724' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,611 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,612 : WARNING : duplicate word '767' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,613 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,615 : WARNING : duplicate word '144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,616 : WARNING : duplicate word '256' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,618 : WARNING : duplicate word '268' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,619 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,621 : WARNING : duplicate word '471' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,622 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,624 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,626 : WARNING : duplicate word '634' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,627 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,628 : WARNING : duplicate word '407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,629 : WARNING : duplicate word '43' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,630 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,633 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,635 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,637 : WARNING : duplicate word '5773' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,638 : WARNING : duplicate word '811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,640 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,641 : WARNING : duplicate word '6005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,642 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,646 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,647 : WARNING : duplicate word '774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,649 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,650 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,651 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,653 : WARNING : duplicate word '734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,654 : WARNING : duplicate word '651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,655 : WARNING : duplicate word '049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,657 : WARNING : duplicate word '966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,658 : WARNING : duplicate word '298' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,659 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,661 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,662 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,664 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,665 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,666 : WARNING : duplicate word '197' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,667 : WARNING : duplicate word '811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,668 : WARNING : duplicate word '1257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,669 : WARNING : duplicate word '595' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,670 : WARNING : duplicate word '016' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,671 : WARNING : duplicate word '6193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,672 : WARNING : duplicate word '829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,673 : WARNING : duplicate word '053' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,674 : WARNING : duplicate word '398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,676 : WARNING : duplicate word '126' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,676 : WARNING : duplicate word '979' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,677 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,679 : WARNING : duplicate word '892' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,680 : WARNING : duplicate word '733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,692 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,697 : WARNING : duplicate word '475' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,698 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,700 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,701 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,702 : WARNING : duplicate word '803' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,704 : WARNING : duplicate word '43' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,705 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,707 : WARNING : duplicate word '391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,708 : WARNING : duplicate word '504' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,709 : WARNING : duplicate word '403' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,711 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,713 : WARNING : duplicate word '443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,716 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,717 : WARNING : duplicate word '775' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,718 : WARNING : duplicate word '524' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,719 : WARNING : duplicate word '854' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,720 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,721 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,722 : WARNING : duplicate word '932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,723 : WARNING : duplicate word '7508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,724 : WARNING : duplicate word '071' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,726 : WARNING : duplicate word '767' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,734 : WARNING : duplicate word '176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,735 : WARNING : duplicate word '272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,736 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,739 : WARNING : duplicate word '675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,740 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,741 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,744 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,747 : WARNING : duplicate word '11' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,749 : WARNING : duplicate word '29' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,750 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,752 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,753 : WARNING : duplicate word '838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,754 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,755 : WARNING : duplicate word '763' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,756 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,757 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,758 : WARNING : duplicate word '013' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,759 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,760 : WARNING : duplicate word '105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,762 : WARNING : duplicate word '261' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,764 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,765 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,766 : WARNING : duplicate word '2524' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,767 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,767 : WARNING : duplicate word '742' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,768 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,769 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,769 : WARNING : duplicate word '277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,770 : WARNING : duplicate word '406' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,772 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,773 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,775 : WARNING : duplicate word '849' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,775 : WARNING : duplicate word '916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,780 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,781 : WARNING : duplicate word '276' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,783 : WARNING : duplicate word '889' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,784 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,785 : WARNING : duplicate word '431' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,787 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,788 : WARNING : duplicate word '127' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,789 : WARNING : duplicate word '753' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,791 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,792 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,793 : WARNING : duplicate word '969' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,794 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,796 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,797 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,798 : WARNING : duplicate word '175' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,800 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,801 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,801 : WARNING : duplicate word '011' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,802 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,802 : WARNING : duplicate word '591' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,803 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,805 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,806 : WARNING : duplicate word '8748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,807 : WARNING : duplicate word '435' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,807 : WARNING : duplicate word '6391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,808 : WARNING : duplicate word '356' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,809 : WARNING : duplicate word '735' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,810 : WARNING : duplicate word '36' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,812 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,813 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,814 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,816 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,816 : WARNING : duplicate word '519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,817 : WARNING : duplicate word '678' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,818 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,819 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,820 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,820 : WARNING : duplicate word '1083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,821 : WARNING : duplicate word '4541' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,822 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,822 : WARNING : duplicate word '366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,823 : WARNING : duplicate word '407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,824 : WARNING : duplicate word '151' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,824 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,825 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,826 : WARNING : duplicate word '049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,826 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,827 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,828 : WARNING : duplicate word '613' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,839 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,840 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,840 : WARNING : duplicate word '908' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,841 : WARNING : duplicate word '173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,842 : WARNING : duplicate word '3793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,844 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,847 : WARNING : duplicate word '544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,847 : WARNING : duplicate word '7128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,848 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,849 : WARNING : duplicate word '056' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,849 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,850 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,850 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,851 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,851 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,852 : WARNING : duplicate word '415' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,852 : WARNING : duplicate word '322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,853 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,856 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,857 : WARNING : duplicate word '071' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,857 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,858 : WARNING : duplicate word '786' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,859 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,861 : WARNING : duplicate word '524' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,863 : WARNING : duplicate word '499' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,864 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,865 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,866 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,867 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,868 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,868 : WARNING : duplicate word '016' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,869 : WARNING : duplicate word '936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,870 : WARNING : duplicate word '488' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,871 : WARNING : duplicate word '411' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,872 : WARNING : duplicate word '679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,872 : WARNING : duplicate word '9135' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,873 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,874 : WARNING : duplicate word '497' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,874 : WARNING : duplicate word '993' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,875 : WARNING : duplicate word '1667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,876 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,876 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,879 : WARNING : duplicate word '331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,880 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,882 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,882 : WARNING : duplicate word '164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,883 : WARNING : duplicate word '8714' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,883 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,884 : WARNING : duplicate word '2838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,885 : WARNING : duplicate word '278' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,885 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,886 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,886 : WARNING : duplicate word '689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,887 : WARNING : duplicate word '447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,888 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,888 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,889 : WARNING : duplicate word '098' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,890 : WARNING : duplicate word '7128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,890 : WARNING : duplicate word '674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,891 : WARNING : duplicate word '3818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,891 : WARNING : duplicate word '12736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,892 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,892 : WARNING : duplicate word '693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,893 : WARNING : duplicate word '8417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,894 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,894 : WARNING : duplicate word '856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,895 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,896 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,896 : WARNING : duplicate word '211' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,897 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,898 : WARNING : duplicate word '4035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,898 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,900 : WARNING : duplicate word '806' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,902 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,903 : WARNING : duplicate word '986' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,905 : WARNING : duplicate word '704' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,906 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,907 : WARNING : duplicate word '643' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,907 : WARNING : duplicate word '936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,908 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,908 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,909 : WARNING : duplicate word '888' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,910 : WARNING : duplicate word '824' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,914 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,915 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,916 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,916 : WARNING : duplicate word '565' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,917 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,918 : WARNING : duplicate word '459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,919 : WARNING : duplicate word '503' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,919 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,920 : WARNING : duplicate word '569' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,921 : WARNING : duplicate word '143' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,922 : WARNING : duplicate word '164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,923 : WARNING : duplicate word '247' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,923 : WARNING : duplicate word '877' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,924 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,925 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,925 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,926 : WARNING : duplicate word '392' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,927 : WARNING : duplicate word '98' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,927 : WARNING : duplicate word '0517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,929 : WARNING : duplicate word '066' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,929 : WARNING : duplicate word '484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,930 : WARNING : duplicate word '272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,931 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,931 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,932 : WARNING : duplicate word '336' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,933 : WARNING : duplicate word '702' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,933 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,934 : WARNING : duplicate word '244' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,935 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,935 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,936 : WARNING : duplicate word '417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,936 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,937 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,938 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,938 : WARNING : duplicate word '033' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,939 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,939 : WARNING : duplicate word '674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,940 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,941 : WARNING : duplicate word '056' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,941 : WARNING : duplicate word '849' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,942 : WARNING : duplicate word '789' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,942 : WARNING : duplicate word '489' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,943 : WARNING : duplicate word '61' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,944 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,944 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,945 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,946 : WARNING : duplicate word '277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,952 : WARNING : duplicate word '318' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,955 : WARNING : duplicate word '927' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,956 : WARNING : duplicate word '972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,956 : WARNING : duplicate word '287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,957 : WARNING : duplicate word '679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,957 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,958 : WARNING : duplicate word '321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,958 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,959 : WARNING : duplicate word '579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,961 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,962 : WARNING : duplicate word '838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,964 : WARNING : duplicate word '354' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,965 : WARNING : duplicate word '447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,966 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,967 : WARNING : duplicate word '256' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,967 : WARNING : duplicate word '321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,968 : WARNING : duplicate word '923' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,968 : WARNING : duplicate word '0029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,969 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,970 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,971 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,971 : WARNING : duplicate word '216' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,972 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,973 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,974 : WARNING : duplicate word '734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,975 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,976 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,976 : WARNING : duplicate word '623' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,977 : WARNING : duplicate word '15' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,977 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,987 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,988 : WARNING : duplicate word '156' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,989 : WARNING : duplicate word '' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:24,995 : WARNING : duplicate word '705' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,997 : WARNING : duplicate word '27' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,998 : WARNING : duplicate word '916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:24,999 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,002 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,004 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,005 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,011 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,015 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,017 : WARNING : duplicate word '105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,018 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,019 : WARNING : duplicate word '3303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,021 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,023 : WARNING : duplicate word '947' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,024 : WARNING : duplicate word '3608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,025 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,026 : WARNING : duplicate word '496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,028 : WARNING : duplicate word '15' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,029 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,030 : WARNING : duplicate word '209' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,031 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,033 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,033 : WARNING : duplicate word '357' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,034 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,035 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,035 : WARNING : duplicate word '968' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,036 : WARNING : duplicate word '852' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,037 : WARNING : duplicate word '7194' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,038 : WARNING : duplicate word '623' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,039 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,039 : WARNING : duplicate word '792' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,040 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,041 : WARNING : duplicate word '168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,041 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,042 : WARNING : duplicate word '663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,050 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,051 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,080 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,081 : WARNING : duplicate word '5238' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,083 : WARNING : duplicate word '8593' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,083 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,084 : WARNING : duplicate word '6459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,085 : WARNING : duplicate word '8748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,086 : WARNING : duplicate word '812' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,086 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,087 : WARNING : duplicate word '8246' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,088 : WARNING : duplicate word '6789' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,089 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,090 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,091 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,092 : WARNING : duplicate word '982' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,092 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,093 : WARNING : duplicate word '974' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,094 : WARNING : duplicate word '3716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,094 : WARNING : duplicate word '952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,095 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,096 : WARNING : duplicate word '934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,097 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,098 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,098 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,099 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,100 : WARNING : duplicate word '506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,100 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,101 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,101 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,102 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,102 : WARNING : duplicate word '2784' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,103 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,104 : WARNING : duplicate word '035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,104 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,105 : WARNING : duplicate word '556' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,106 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,106 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,107 : WARNING : duplicate word '1164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,107 : WARNING : duplicate word '094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,108 : WARNING : duplicate word '716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,109 : WARNING : duplicate word '478' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,109 : WARNING : duplicate word '222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,110 : WARNING : duplicate word '682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,112 : WARNING : duplicate word '988' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,114 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,115 : WARNING : duplicate word '127' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,116 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,117 : WARNING : duplicate word '733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,118 : WARNING : duplicate word '427' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,119 : WARNING : duplicate word '073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,119 : WARNING : duplicate word '9532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,120 : WARNING : duplicate word '936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,123 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,124 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,125 : WARNING : duplicate word '9048' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,126 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,128 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,131 : WARNING : duplicate word '8389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,132 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,133 : WARNING : duplicate word '007' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,134 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,135 : WARNING : duplicate word '818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,137 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,138 : WARNING : duplicate word '1294' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,138 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,140 : WARNING : duplicate word '733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,141 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,142 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,142 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,144 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,146 : WARNING : duplicate word '529' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,146 : WARNING : duplicate word '907' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,147 : WARNING : duplicate word '8036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,148 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,149 : WARNING : duplicate word '525' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,150 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,151 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,152 : WARNING : duplicate word '866' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,152 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,154 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,156 : WARNING : duplicate word '682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,157 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,158 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,158 : WARNING : duplicate word '296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,159 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,160 : WARNING : duplicate word '4' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,160 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,161 : WARNING : duplicate word '856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,163 : WARNING : duplicate word '997' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,164 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,170 : WARNING : duplicate word '533' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,178 : WARNING : duplicate word '499' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,180 : WARNING : duplicate word '053' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,181 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,183 : WARNING : duplicate word '321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,185 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,186 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,187 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,188 : WARNING : duplicate word '393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,189 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,191 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,192 : WARNING : duplicate word '322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,193 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,195 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,196 : WARNING : duplicate word '071' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,197 : WARNING : duplicate word '8482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,199 : WARNING : duplicate word '5425' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,200 : WARNING : duplicate word '38' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,201 : WARNING : duplicate word '544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,202 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,205 : WARNING : duplicate word '0244' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,207 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,208 : WARNING : duplicate word '7814' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,209 : WARNING : duplicate word '98' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,211 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,213 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,214 : WARNING : duplicate word '031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,216 : WARNING : duplicate word '722' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,217 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,218 : WARNING : duplicate word '716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,219 : WARNING : duplicate word '36' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,221 : WARNING : duplicate word '6271' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,222 : WARNING : duplicate word '092' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,223 : WARNING : duplicate word '764' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,224 : WARNING : duplicate word '683' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,225 : WARNING : duplicate word '315' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,226 : WARNING : duplicate word '958' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,227 : WARNING : duplicate word '277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,233 : WARNING : duplicate word '5746' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,234 : WARNING : duplicate word '324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,235 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,237 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,239 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,240 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,240 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,241 : WARNING : duplicate word '742' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,241 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,242 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,243 : WARNING : duplicate word '313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,243 : WARNING : duplicate word '1198' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,244 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,246 : WARNING : duplicate word '964' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,247 : WARNING : duplicate word '407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,248 : WARNING : duplicate word '8807' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,249 : WARNING : duplicate word '888' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,250 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,251 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,251 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,252 : WARNING : duplicate word '573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,253 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,254 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,258 : WARNING : duplicate word '089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,259 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,260 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,265 : WARNING : duplicate word '631' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,267 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,268 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,269 : WARNING : duplicate word '197' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,270 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,271 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,273 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,273 : WARNING : duplicate word '7659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,274 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,275 : WARNING : duplicate word '7049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,276 : WARNING : duplicate word '044' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,277 : WARNING : duplicate word '708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,279 : WARNING : duplicate word '975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,280 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,281 : WARNING : duplicate word '626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,290 : WARNING : duplicate word '352' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,291 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,292 : WARNING : duplicate word '004' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,293 : WARNING : duplicate word '963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,294 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,295 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,296 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,297 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,299 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,300 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,305 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,306 : WARNING : duplicate word '079' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,307 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,308 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,309 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,312 : WARNING : duplicate word '427' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,313 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,315 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,317 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,319 : WARNING : duplicate word '3322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,321 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,323 : WARNING : duplicate word '4086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,324 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,325 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,326 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,329 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,330 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,331 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,333 : WARNING : duplicate word '879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,334 : WARNING : duplicate word '704' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,335 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,336 : WARNING : duplicate word '801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,367 : WARNING : duplicate word '8' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,368 : WARNING : duplicate word '61' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,369 : WARNING : duplicate word '282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,370 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,374 : WARNING : duplicate word '9959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,375 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,377 : WARNING : duplicate word '5796' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,378 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,380 : WARNING : duplicate word '824' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,381 : WARNING : duplicate word '835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,383 : WARNING : duplicate word '182' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,385 : WARNING : duplicate word '6111' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,386 : WARNING : duplicate word '7732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,387 : WARNING : duplicate word '037' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,389 : WARNING : duplicate word '466' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,390 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,391 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,392 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,393 : WARNING : duplicate word '188' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,395 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,396 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,397 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,398 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,399 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,400 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,403 : WARNING : duplicate word '928' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,407 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,409 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,410 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,410 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,411 : WARNING : duplicate word '548' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,412 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,413 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,414 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,415 : WARNING : duplicate word '16' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,416 : WARNING : duplicate word '819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,417 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,423 : WARNING : duplicate word '3072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,424 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,425 : WARNING : duplicate word '067' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,426 : WARNING : duplicate word '728' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,430 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,432 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,434 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,435 : WARNING : duplicate word '308' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,435 : WARNING : duplicate word '36' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,436 : WARNING : duplicate word '254' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,437 : WARNING : duplicate word '328' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,438 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,439 : WARNING : duplicate word '503' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,441 : WARNING : duplicate word '841' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,441 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,442 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,443 : WARNING : duplicate word '623' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,443 : WARNING : duplicate word '718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,444 : WARNING : duplicate word '1287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,444 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,446 : WARNING : duplicate word '7105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,448 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,449 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,454 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,455 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,456 : WARNING : duplicate word '725' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,457 : WARNING : duplicate word '653' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,461 : WARNING : duplicate word '505' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,462 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,463 : WARNING : duplicate word '251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,463 : WARNING : duplicate word '964' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,464 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,465 : WARNING : duplicate word '329' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,466 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,466 : WARNING : duplicate word '424' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,467 : WARNING : duplicate word '69' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,469 : WARNING : duplicate word '889' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,472 : WARNING : duplicate word '229' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,473 : WARNING : duplicate word '62' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,474 : WARNING : duplicate word '5533' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,474 : WARNING : duplicate word '9133' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,476 : WARNING : duplicate word '932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,480 : WARNING : duplicate word '054' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,482 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,483 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,484 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,485 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,486 : WARNING : duplicate word '383' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,487 : WARNING : duplicate word '088' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,488 : WARNING : duplicate word '8967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,491 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,491 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,492 : WARNING : duplicate word '365' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,494 : WARNING : duplicate word '6413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,495 : WARNING : duplicate word '371' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,496 : WARNING : duplicate word '0804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,497 : WARNING : duplicate word '4798' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,499 : WARNING : duplicate word '5024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,500 : WARNING : duplicate word '9544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,501 : WARNING : duplicate word '2939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,502 : WARNING : duplicate word '927' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,502 : WARNING : duplicate word '277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,505 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,506 : WARNING : duplicate word '479' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,507 : WARNING : duplicate word '61' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,507 : WARNING : duplicate word '481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,508 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,509 : WARNING : duplicate word '9878' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,510 : WARNING : duplicate word '573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,511 : WARNING : duplicate word '224' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,513 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,515 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,516 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,517 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,518 : WARNING : duplicate word '863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,519 : WARNING : duplicate word '576' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,521 : WARNING : duplicate word '181' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,523 : WARNING : duplicate word '229' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,524 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,525 : WARNING : duplicate word '461' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,526 : WARNING : duplicate word '247' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,527 : WARNING : duplicate word '9622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,528 : WARNING : duplicate word '551' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,529 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,530 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,531 : WARNING : duplicate word '372' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,532 : WARNING : duplicate word '092' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,533 : WARNING : duplicate word '937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,533 : WARNING : duplicate word '443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,534 : WARNING : duplicate word '468' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,535 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,536 : WARNING : duplicate word '4484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,540 : WARNING : duplicate word '478' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,541 : WARNING : duplicate word '366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,542 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,543 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,544 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,544 : WARNING : duplicate word '5487' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,545 : WARNING : duplicate word '824' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,546 : WARNING : duplicate word '098' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,547 : WARNING : duplicate word '69' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,547 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,548 : WARNING : duplicate word '064' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,549 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,549 : WARNING : duplicate word '287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,550 : WARNING : duplicate word '93' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,551 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,552 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,552 : WARNING : duplicate word '4' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,553 : WARNING : duplicate word '005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,555 : WARNING : duplicate word '7166' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,556 : WARNING : duplicate word '391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,557 : WARNING : duplicate word '892' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,558 : WARNING : duplicate word '913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,561 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,563 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,565 : WARNING : duplicate word '021' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,566 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,567 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,568 : WARNING : duplicate word '121' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,569 : WARNING : duplicate word '9152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,571 : WARNING : duplicate word '388' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,572 : WARNING : duplicate word '5506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,573 : WARNING : duplicate word '96' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,573 : WARNING : duplicate word '481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,574 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,575 : WARNING : duplicate word '373' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,576 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,577 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,578 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,579 : WARNING : duplicate word '3835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,580 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,581 : WARNING : duplicate word '885' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,583 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,584 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,585 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,586 : WARNING : duplicate word '745' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,586 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,588 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,589 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,590 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,591 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,592 : WARNING : duplicate word '247' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,592 : WARNING : duplicate word '58' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,593 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,595 : WARNING : duplicate word '578' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,597 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,599 : WARNING : duplicate word '366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,600 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,601 : WARNING : duplicate word '331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,602 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,603 : WARNING : duplicate word '693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,605 : WARNING : duplicate word '642' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,606 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,606 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,608 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,609 : WARNING : duplicate word '9658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,610 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,611 : WARNING : duplicate word '3303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,612 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,613 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,614 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,615 : WARNING : duplicate word '463' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,646 : WARNING : duplicate word '652' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,647 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,649 : WARNING : duplicate word '079' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,650 : WARNING : duplicate word '9981' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,651 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,652 : WARNING : duplicate word '519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,653 : WARNING : duplicate word '562' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,654 : WARNING : duplicate word '302' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,655 : WARNING : duplicate word '412' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,656 : WARNING : duplicate word '5949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,662 : WARNING : duplicate word '257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,663 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,664 : WARNING : duplicate word '679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,665 : WARNING : duplicate word '035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,665 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,666 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,667 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,668 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,669 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,670 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,672 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,674 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,675 : WARNING : duplicate word '912' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,676 : WARNING : duplicate word '268' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,676 : WARNING : duplicate word '947' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,677 : WARNING : duplicate word '164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,678 : WARNING : duplicate word '221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,679 : WARNING : duplicate word '334' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,680 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,683 : WARNING : duplicate word '542' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,684 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,685 : WARNING : duplicate word '066' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,686 : WARNING : duplicate word '448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,688 : WARNING : duplicate word '176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,690 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,691 : WARNING : duplicate word '402' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,692 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,693 : WARNING : duplicate word '573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,697 : WARNING : duplicate word '516' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,699 : WARNING : duplicate word '6494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,700 : WARNING : duplicate word '7237' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,701 : WARNING : duplicate word '076' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,701 : WARNING : duplicate word '' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,702 : WARNING : duplicate word '315' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,703 : WARNING : duplicate word '27' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,704 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,705 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,706 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,706 : WARNING : duplicate word '928' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,707 : WARNING : duplicate word '263' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,707 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,708 : WARNING : duplicate word '6685' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,709 : WARNING : duplicate word '164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,709 : WARNING : duplicate word '013' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,710 : WARNING : duplicate word '5413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,711 : WARNING : duplicate word '428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,712 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,713 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,714 : WARNING : duplicate word '63032' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,715 : WARNING : duplicate word '58' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,715 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,716 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,717 : WARNING : duplicate word '6519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,720 : WARNING : duplicate word '474' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,721 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,723 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,724 : WARNING : duplicate word '7105' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,729 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,730 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,732 : WARNING : duplicate word '173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,733 : WARNING : duplicate word '696' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,734 : WARNING : duplicate word '1937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,735 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,736 : WARNING : duplicate word '709' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,737 : WARNING : duplicate word '351' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,740 : WARNING : duplicate word '2784' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,741 : WARNING : duplicate word '7275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,742 : WARNING : duplicate word '7151' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,745 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,746 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,747 : WARNING : duplicate word '468' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,749 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,750 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,751 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,751 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,754 : WARNING : duplicate word '272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,757 : WARNING : duplicate word '1741' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,757 : WARNING : duplicate word '534' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,758 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,758 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,759 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,759 : WARNING : duplicate word '805' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,760 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,761 : WARNING : duplicate word '6788' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,762 : WARNING : duplicate word '8625' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,763 : WARNING : duplicate word '495' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,763 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,764 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,765 : WARNING : duplicate word '934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,765 : WARNING : duplicate word '651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,766 : WARNING : duplicate word '8714' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,767 : WARNING : duplicate word '648' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,767 : WARNING : duplicate word '468' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,768 : WARNING : duplicate word '642' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,769 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,771 : WARNING : duplicate word '663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,773 : WARNING : duplicate word '015' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,774 : WARNING : duplicate word '8675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,775 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,778 : WARNING : duplicate word '5268' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,780 : WARNING : duplicate word '5671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,781 : WARNING : duplicate word '214' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,784 : WARNING : duplicate word '639' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,786 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,786 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,789 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,790 : WARNING : duplicate word '96' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,793 : WARNING : duplicate word '605' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,794 : WARNING : duplicate word '731' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,795 : WARNING : duplicate word '192' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,797 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,800 : WARNING : duplicate word '379' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,801 : WARNING : duplicate word '678' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,802 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,803 : WARNING : duplicate word '7525' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,804 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,806 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,807 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,808 : WARNING : duplicate word '182' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,816 : WARNING : duplicate word '325' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,822 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,828 : WARNING : duplicate word '674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,829 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,831 : WARNING : duplicate word '006' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,833 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,835 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,836 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,838 : WARNING : duplicate word '642' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,839 : WARNING : duplicate word '253' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,840 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,844 : WARNING : duplicate word '441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,845 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,846 : WARNING : duplicate word '7166' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,847 : WARNING : duplicate word '806' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,849 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,850 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,851 : WARNING : duplicate word '809' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,852 : WARNING : duplicate word '557' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,854 : WARNING : duplicate word '754' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,856 : WARNING : duplicate word '1044' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,857 : WARNING : duplicate word '908' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,858 : WARNING : duplicate word '303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,859 : WARNING : duplicate word '0304' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,860 : WARNING : duplicate word '315' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,866 : WARNING : duplicate word '196' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,868 : WARNING : duplicate word '615' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,874 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,876 : WARNING : duplicate word '805' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,884 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,889 : WARNING : duplicate word '044' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,890 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,892 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,893 : WARNING : duplicate word '913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,894 : WARNING : duplicate word '148' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,895 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,897 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,901 : WARNING : duplicate word '481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,902 : WARNING : duplicate word '906' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,903 : WARNING : duplicate word '945' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,905 : WARNING : duplicate word '324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,907 : WARNING : duplicate word '735' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,908 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,909 : WARNING : duplicate word '5273' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,910 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,917 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,918 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,920 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,921 : WARNING : duplicate word '68' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,922 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,923 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,924 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,925 : WARNING : duplicate word '242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,927 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,928 : WARNING : duplicate word '104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,929 : WARNING : duplicate word '993' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,930 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,931 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,932 : WARNING : duplicate word '143' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,933 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,934 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,936 : WARNING : duplicate word '085' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,937 : WARNING : duplicate word '656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,938 : WARNING : duplicate word '305' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,939 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,940 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,942 : WARNING : duplicate word '093' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,943 : WARNING : duplicate word '466' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,944 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,945 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,975 : WARNING : duplicate word '36' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,976 : WARNING : duplicate word '8867' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,977 : WARNING : duplicate word '6699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,978 : WARNING : duplicate word '263' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,979 : WARNING : duplicate word '2162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,980 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,981 : WARNING : duplicate word '819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,982 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,984 : WARNING : duplicate word '09' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,986 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,987 : WARNING : duplicate word '387' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,990 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:25,992 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,993 : WARNING : duplicate word '489' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,996 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:25,998 : WARNING : duplicate word '667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,001 : WARNING : duplicate word '2829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,002 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,003 : WARNING : duplicate word '988' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,004 : WARNING : duplicate word '604' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,005 : WARNING : duplicate word '901' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,006 : WARNING : duplicate word '858' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,007 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,008 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,009 : WARNING : duplicate word '322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,010 : WARNING : duplicate word '247' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,015 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,016 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,018 : WARNING : duplicate word '667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,019 : WARNING : duplicate word '287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,020 : WARNING : duplicate word '791' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,021 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,022 : WARNING : duplicate word '403' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,023 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,023 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,024 : WARNING : duplicate word '863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,025 : WARNING : duplicate word '302' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,026 : WARNING : duplicate word '898' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,027 : WARNING : duplicate word '141' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,028 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,031 : WARNING : duplicate word '458' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,032 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,033 : WARNING : duplicate word '023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,033 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,037 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,045 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,046 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,047 : WARNING : duplicate word '352' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,048 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,050 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,051 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,052 : WARNING : duplicate word '585' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,053 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,055 : WARNING : duplicate word '716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,057 : WARNING : duplicate word '733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,058 : WARNING : duplicate word '588' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,059 : WARNING : duplicate word '251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,062 : WARNING : duplicate word '6963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,064 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,065 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,066 : WARNING : duplicate word '7316' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,067 : WARNING : duplicate word '739' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,068 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,069 : WARNING : duplicate word '0593' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,070 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,071 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,072 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,073 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,074 : WARNING : duplicate word '738' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,074 : WARNING : duplicate word '829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,075 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,078 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,079 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,080 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,082 : WARNING : duplicate word '6313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,083 : WARNING : duplicate word '127' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,084 : WARNING : duplicate word '5123' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,085 : WARNING : duplicate word '4081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,085 : WARNING : duplicate word '595' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,086 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,087 : WARNING : duplicate word '864' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,089 : WARNING : duplicate word '658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,090 : WARNING : duplicate word '3536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,091 : WARNING : duplicate word '022' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,092 : WARNING : duplicate word '546' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,093 : WARNING : duplicate word '787' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,095 : WARNING : duplicate word '4086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,097 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,097 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,099 : WARNING : duplicate word '717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,100 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,100 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,101 : WARNING : duplicate word '639' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,102 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,103 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,103 : WARNING : duplicate word '674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,104 : WARNING : duplicate word '6131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,105 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,105 : WARNING : duplicate word '936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,106 : WARNING : duplicate word '885' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,107 : WARNING : duplicate word '022' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,107 : WARNING : duplicate word '135' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,108 : WARNING : duplicate word '293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,108 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,109 : WARNING : duplicate word '372' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,109 : WARNING : duplicate word '2909' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,110 : WARNING : duplicate word '719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,112 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,113 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,114 : WARNING : duplicate word '335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,115 : WARNING : duplicate word '567' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,116 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,117 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,117 : WARNING : duplicate word '174' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,118 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,119 : WARNING : duplicate word '351' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,119 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,120 : WARNING : duplicate word '569' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,122 : WARNING : duplicate word '041' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,123 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,124 : WARNING : duplicate word '162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,124 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,125 : WARNING : duplicate word '768' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,126 : WARNING : duplicate word '641' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,126 : WARNING : duplicate word '831' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,127 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,129 : WARNING : duplicate word '502' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,130 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,131 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,132 : WARNING : duplicate word '5104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,133 : WARNING : duplicate word '4046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,133 : WARNING : duplicate word '289' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,135 : WARNING : duplicate word '744' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,135 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,136 : WARNING : duplicate word '5936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,137 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,137 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,138 : WARNING : duplicate word '728' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,139 : WARNING : duplicate word '573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,140 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,140 : WARNING : duplicate word '073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,141 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,142 : WARNING : duplicate word '9959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,143 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,144 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,144 : WARNING : duplicate word '111' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,145 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,146 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,147 : WARNING : duplicate word '742' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,148 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,149 : WARNING : duplicate word '4168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,149 : WARNING : duplicate word '2312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,150 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,151 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,151 : WARNING : duplicate word '398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,152 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,152 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,153 : WARNING : duplicate word '257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,154 : WARNING : duplicate word '221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,155 : WARNING : duplicate word '714' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,155 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,156 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,156 : WARNING : duplicate word '533' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,157 : WARNING : duplicate word '681' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,158 : WARNING : duplicate word '3045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,159 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,161 : WARNING : duplicate word '964' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,162 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,163 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,163 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,166 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,167 : WARNING : duplicate word '7108' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,168 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,168 : WARNING : duplicate word '043' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,169 : WARNING : duplicate word '5249' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,169 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,170 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,171 : WARNING : duplicate word '697' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,172 : WARNING : duplicate word '576' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,173 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,173 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,174 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,175 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,176 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,178 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,180 : WARNING : duplicate word '221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,181 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,183 : WARNING : duplicate word '891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,184 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,185 : WARNING : duplicate word '915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,186 : WARNING : duplicate word '089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,187 : WARNING : duplicate word '6266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,188 : WARNING : duplicate word '5899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,189 : WARNING : duplicate word '474' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,190 : WARNING : duplicate word '477' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,191 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,192 : WARNING : duplicate word '531' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,193 : WARNING : duplicate word '952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,194 : WARNING : duplicate word '593' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,195 : WARNING : duplicate word '456' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,240 : WARNING : duplicate word '418' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,241 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,242 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,243 : WARNING : duplicate word '696' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,244 : WARNING : duplicate word '134' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,245 : WARNING : duplicate word '795' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,246 : WARNING : duplicate word '926' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,246 : WARNING : duplicate word '093' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,247 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,248 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,249 : WARNING : duplicate word '848' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,249 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,250 : WARNING : duplicate word '7219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,251 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,251 : WARNING : duplicate word '2808' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,252 : WARNING : duplicate word '444' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,252 : WARNING : duplicate word '509' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,253 : WARNING : duplicate word '787' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,254 : WARNING : duplicate word '539' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,254 : WARNING : duplicate word '732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,257 : WARNING : duplicate word '1164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,258 : WARNING : duplicate word '157' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,259 : WARNING : duplicate word '679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,263 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,264 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,265 : WARNING : duplicate word '09' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,266 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,267 : WARNING : duplicate word '653' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,268 : WARNING : duplicate word '406' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,269 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,270 : WARNING : duplicate word '4136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,271 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,272 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,273 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,274 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,275 : WARNING : duplicate word '1658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,276 : WARNING : duplicate word '0659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,277 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,278 : WARNING : duplicate word '492' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,279 : WARNING : duplicate word '217' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,280 : WARNING : duplicate word '708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,281 : WARNING : duplicate word '9549' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,282 : WARNING : duplicate word '623' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,283 : WARNING : duplicate word '421' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,284 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,285 : WARNING : duplicate word '066' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,286 : WARNING : duplicate word '753' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,287 : WARNING : duplicate word '509' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,288 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,289 : WARNING : duplicate word '023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,290 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,291 : WARNING : duplicate word '254' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,292 : WARNING : duplicate word '519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,292 : WARNING : duplicate word '344' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,293 : WARNING : duplicate word '8371' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,294 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,295 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,296 : WARNING : duplicate word '536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,297 : WARNING : duplicate word '4541' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,298 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,298 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,299 : WARNING : duplicate word '6031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,300 : WARNING : duplicate word '816' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,301 : WARNING : duplicate word '414' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,302 : WARNING : duplicate word '313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,303 : WARNING : duplicate word '894' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,304 : WARNING : duplicate word '393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,305 : WARNING : duplicate word '788' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,306 : WARNING : duplicate word '095' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,307 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,308 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,308 : WARNING : duplicate word '3242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,309 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,311 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,313 : WARNING : duplicate word '951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,314 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,315 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,325 : WARNING : duplicate word '648' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,326 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,327 : WARNING : duplicate word '432' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,329 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,330 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,330 : WARNING : duplicate word '551' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,331 : WARNING : duplicate word '026' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,334 : WARNING : duplicate word '218' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,336 : WARNING : duplicate word '056' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,339 : WARNING : duplicate word '016' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,340 : WARNING : duplicate word '603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,341 : WARNING : duplicate word '923' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,342 : WARNING : duplicate word '463' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,346 : WARNING : duplicate word '578' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,347 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,349 : WARNING : duplicate word '209' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,350 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,351 : WARNING : duplicate word '6628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,357 : WARNING : duplicate word '102' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,358 : WARNING : duplicate word '109' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,359 : WARNING : duplicate word '524' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,360 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,361 : WARNING : duplicate word '536' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,362 : WARNING : duplicate word '6789' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,363 : WARNING : duplicate word '89' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,364 : WARNING : duplicate word '719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,365 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,366 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,367 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,368 : WARNING : duplicate word '3077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,369 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,371 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,373 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,374 : WARNING : duplicate word '865' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,375 : WARNING : duplicate word '387' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,376 : WARNING : duplicate word '511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,378 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,380 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,382 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,383 : WARNING : duplicate word '0003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,384 : WARNING : duplicate word '416' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,385 : WARNING : duplicate word '692' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,386 : WARNING : duplicate word '206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,393 : WARNING : duplicate word '7317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,394 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,395 : WARNING : duplicate word '5353' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,396 : WARNING : duplicate word '665' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,398 : WARNING : duplicate word '343' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,399 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,400 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,401 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,402 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,406 : WARNING : duplicate word '231' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,407 : WARNING : duplicate word '565' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,408 : WARNING : duplicate word '374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,409 : WARNING : duplicate word '4296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,413 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,414 : WARNING : duplicate word '728' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,416 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,417 : WARNING : duplicate word '595' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,418 : WARNING : duplicate word '754' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,420 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,421 : WARNING : duplicate word '295' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,423 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,423 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,424 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,425 : WARNING : duplicate word '387' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,425 : WARNING : duplicate word '1011' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,426 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,429 : WARNING : duplicate word '3486' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,430 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,432 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,433 : WARNING : duplicate word '785' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,434 : WARNING : duplicate word '15' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,435 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,436 : WARNING : duplicate word '31' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,437 : WARNING : duplicate word '1221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,439 : WARNING : duplicate word '1029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,439 : WARNING : duplicate word '8461' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,440 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,441 : WARNING : duplicate word '658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,442 : WARNING : duplicate word '083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,443 : WARNING : duplicate word '142' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,445 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,446 : WARNING : duplicate word '379' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,447 : WARNING : duplicate word '315' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,448 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,448 : WARNING : duplicate word '898' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,450 : WARNING : duplicate word '646' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,451 : WARNING : duplicate word '151' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,452 : WARNING : duplicate word '539' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,453 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,454 : WARNING : duplicate word '386' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,455 : WARNING : duplicate word '0674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,456 : WARNING : duplicate word '755' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,457 : WARNING : duplicate word '127' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,458 : WARNING : duplicate word '876' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,459 : WARNING : duplicate word '3052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,459 : WARNING : duplicate word '7377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,460 : WARNING : duplicate word '836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,461 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,462 : WARNING : duplicate word '0589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,463 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,464 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,465 : WARNING : duplicate word '447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,466 : WARNING : duplicate word '069' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,467 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,468 : WARNING : duplicate word '0145' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,469 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,469 : WARNING : duplicate word '792' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,470 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,471 : WARNING : duplicate word '531' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,472 : WARNING : duplicate word '335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,473 : WARNING : duplicate word '648' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,481 : WARNING : duplicate word '554' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,482 : WARNING : duplicate word '4584' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,483 : WARNING : duplicate word '782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,484 : WARNING : duplicate word '4' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,486 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,487 : WARNING : duplicate word '549' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,489 : WARNING : duplicate word '2386' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,491 : WARNING : duplicate word '026' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,516 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,517 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,518 : WARNING : duplicate word '986' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,519 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,522 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,524 : WARNING : duplicate word '007' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,525 : WARNING : duplicate word '206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,525 : WARNING : duplicate word '303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,527 : WARNING : duplicate word '598' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,531 : WARNING : duplicate word '414' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,533 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,534 : WARNING : duplicate word '121' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,537 : WARNING : duplicate word '429' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,538 : WARNING : duplicate word '093' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,539 : WARNING : duplicate word '998' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,540 : WARNING : duplicate word '482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,541 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,543 : WARNING : duplicate word '856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,544 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,545 : WARNING : duplicate word '189' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,546 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,547 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,548 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,549 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,554 : WARNING : duplicate word '9757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,556 : WARNING : duplicate word '564' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,558 : WARNING : duplicate word '015' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,559 : WARNING : duplicate word '4614' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,562 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,563 : WARNING : duplicate word '931' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,564 : WARNING : duplicate word '678' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,565 : WARNING : duplicate word '277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,567 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,567 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,568 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,569 : WARNING : duplicate word '844' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,570 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,572 : WARNING : duplicate word '896' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,573 : WARNING : duplicate word '7938' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,574 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,575 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,575 : WARNING : duplicate word '4759' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,576 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,577 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,581 : WARNING : duplicate word '328' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,587 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,589 : WARNING : duplicate word '709' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,590 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,591 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,593 : WARNING : duplicate word '61' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,594 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,595 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,595 : WARNING : duplicate word '5521' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,596 : WARNING : duplicate word '6713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,597 : WARNING : duplicate word '293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,597 : WARNING : duplicate word '3698' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,598 : WARNING : duplicate word '975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,599 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,600 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,601 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,602 : WARNING : duplicate word '775' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,602 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,603 : WARNING : duplicate word '147' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,604 : WARNING : duplicate word '5351' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,607 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,608 : WARNING : duplicate word '689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,609 : WARNING : duplicate word '7297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,610 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,610 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,615 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,616 : WARNING : duplicate word '5689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,617 : WARNING : duplicate word '879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,618 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,619 : WARNING : duplicate word '222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,619 : WARNING : duplicate word '671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,620 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,622 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,622 : WARNING : duplicate word '633' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,623 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,624 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,624 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,626 : WARNING : duplicate word '415' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,627 : WARNING : duplicate word '037' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,633 : WARNING : duplicate word '946' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,636 : WARNING : duplicate word '809' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,637 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,637 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,640 : WARNING : duplicate word '981' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,640 : WARNING : duplicate word '249' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,642 : WARNING : duplicate word '482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,644 : WARNING : duplicate word '531' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,647 : WARNING : duplicate word '7508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,649 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,651 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,652 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,653 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,653 : WARNING : duplicate word '477' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,654 : WARNING : duplicate word '361' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,655 : WARNING : duplicate word '293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,656 : WARNING : duplicate word '798' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,657 : WARNING : duplicate word '111' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,658 : WARNING : duplicate word '539' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,659 : WARNING : duplicate word '787' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,659 : WARNING : duplicate word '454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,660 : WARNING : duplicate word '398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,662 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,663 : WARNING : duplicate word '8768' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,664 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,665 : WARNING : duplicate word '955' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,666 : WARNING : duplicate word '301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,666 : WARNING : duplicate word '3005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,667 : WARNING : duplicate word '668' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,668 : WARNING : duplicate word '335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,668 : WARNING : duplicate word '428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,669 : WARNING : duplicate word '809' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,670 : WARNING : duplicate word '251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,671 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,673 : WARNING : duplicate word '041' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,673 : WARNING : duplicate word '275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,674 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,676 : WARNING : duplicate word '5731' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,677 : WARNING : duplicate word '919' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,678 : WARNING : duplicate word '5959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,679 : WARNING : duplicate word '1364' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,680 : WARNING : duplicate word '4512' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,680 : WARNING : duplicate word '5654' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,681 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,682 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,683 : WARNING : duplicate word '4937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,684 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,684 : WARNING : duplicate word '603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,685 : WARNING : duplicate word '8591' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,686 : WARNING : duplicate word '472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,686 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,688 : WARNING : duplicate word '119' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,689 : WARNING : duplicate word '874' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,690 : WARNING : duplicate word '518' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,692 : WARNING : duplicate word '6968' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,693 : WARNING : duplicate word '482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,693 : WARNING : duplicate word '5324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,696 : WARNING : duplicate word '798' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,697 : WARNING : duplicate word '496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,698 : WARNING : duplicate word '066' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,699 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,700 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,701 : WARNING : duplicate word '818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,702 : WARNING : duplicate word '535' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,702 : WARNING : duplicate word '213' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,703 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,703 : WARNING : duplicate word '8548' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,705 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,705 : WARNING : duplicate word '886' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,706 : WARNING : duplicate word '413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,706 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,707 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,708 : WARNING : duplicate word '001' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,708 : WARNING : duplicate word '339' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,709 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,709 : WARNING : duplicate word '793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,710 : WARNING : duplicate word '5657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,710 : WARNING : duplicate word '473' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,711 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,712 : WARNING : duplicate word '1319' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,712 : WARNING : duplicate word '795' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,713 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,714 : WARNING : duplicate word '801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,714 : WARNING : duplicate word '997' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,715 : WARNING : duplicate word '783' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,715 : WARNING : duplicate word '3825' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,716 : WARNING : duplicate word '968' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,716 : WARNING : duplicate word '525' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,717 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,718 : WARNING : duplicate word '437' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,721 : WARNING : duplicate word '654' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,723 : WARNING : duplicate word '6511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,724 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,724 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,725 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,725 : WARNING : duplicate word '672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,726 : WARNING : duplicate word '251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,727 : WARNING : duplicate word '95' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,727 : WARNING : duplicate word '939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,729 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,730 : WARNING : duplicate word '196' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,730 : WARNING : duplicate word '937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,731 : WARNING : duplicate word '241' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,732 : WARNING : duplicate word '747' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,741 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,744 : WARNING : duplicate word '5492' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,745 : WARNING : duplicate word '2362' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,746 : WARNING : duplicate word '123' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,747 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,749 : WARNING : duplicate word '412' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,750 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,751 : WARNING : duplicate word '8557' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,752 : WARNING : duplicate word '156' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,753 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,754 : WARNING : duplicate word '4027' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,755 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,757 : WARNING : duplicate word '6432' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,771 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,773 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,773 : WARNING : duplicate word '69' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,774 : WARNING : duplicate word '059' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,775 : WARNING : duplicate word '663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,776 : WARNING : duplicate word '127' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,778 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,779 : WARNING : duplicate word '2829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,780 : WARNING : duplicate word '895' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,782 : WARNING : duplicate word '126' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,783 : WARNING : duplicate word '618' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,786 : WARNING : duplicate word '313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,787 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,790 : WARNING : duplicate word '368' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,791 : WARNING : duplicate word '035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,792 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,793 : WARNING : duplicate word '778' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,794 : WARNING : duplicate word '702' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,795 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,796 : WARNING : duplicate word '511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,798 : WARNING : duplicate word '4934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,799 : WARNING : duplicate word '513' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,800 : WARNING : duplicate word '5924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,801 : WARNING : duplicate word '877' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,802 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,804 : WARNING : duplicate word '885' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,806 : WARNING : duplicate word '9262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,807 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,808 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,809 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,814 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,815 : WARNING : duplicate word '967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,816 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,817 : WARNING : duplicate word '276' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,818 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,819 : WARNING : duplicate word '001' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,820 : WARNING : duplicate word '786' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,821 : WARNING : duplicate word '006' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,821 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,822 : WARNING : duplicate word '192' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,823 : WARNING : duplicate word '383' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,823 : WARNING : duplicate word '8884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,824 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,824 : WARNING : duplicate word '84' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,825 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,826 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,826 : WARNING : duplicate word '5561' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,827 : WARNING : duplicate word '718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,828 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,829 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,829 : WARNING : duplicate word '646' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,830 : WARNING : duplicate word '351' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,831 : WARNING : duplicate word '308' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,831 : WARNING : duplicate word '768' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,832 : WARNING : duplicate word '4324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,832 : WARNING : duplicate word '173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,833 : WARNING : duplicate word '1736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,834 : WARNING : duplicate word '959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,834 : WARNING : duplicate word '4114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,835 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,835 : WARNING : duplicate word '075' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,836 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,836 : WARNING : duplicate word '7371' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,837 : WARNING : duplicate word '3693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,837 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,838 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,838 : WARNING : duplicate word '3279' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,839 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,839 : WARNING : duplicate word '851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,840 : WARNING : duplicate word '793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,841 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,841 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,842 : WARNING : duplicate word '036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,844 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,845 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,847 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,848 : WARNING : duplicate word '9445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,848 : WARNING : duplicate word '778' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,849 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,850 : WARNING : duplicate word '503' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,850 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,851 : WARNING : duplicate word '088' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,851 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,852 : WARNING : duplicate word '536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,853 : WARNING : duplicate word '681' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,854 : WARNING : duplicate word '8928' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,856 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,857 : WARNING : duplicate word '982' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,857 : WARNING : duplicate word '397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,858 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,858 : WARNING : duplicate word '841' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,859 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,860 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,863 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,864 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,864 : WARNING : duplicate word '095' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,866 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,867 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,867 : WARNING : duplicate word '7756' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,868 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,869 : WARNING : duplicate word '8303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,869 : WARNING : duplicate word '472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,870 : WARNING : duplicate word '319' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,871 : WARNING : duplicate word '475' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,871 : WARNING : duplicate word '993' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,872 : WARNING : duplicate word '8121' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,874 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,874 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,875 : WARNING : duplicate word '6715' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,875 : WARNING : duplicate word '2998' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,876 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,876 : WARNING : duplicate word '055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,877 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,877 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,878 : WARNING : duplicate word '749' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,879 : WARNING : duplicate word '7597' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,879 : WARNING : duplicate word '796' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,880 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,880 : WARNING : duplicate word '68' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,881 : WARNING : duplicate word '776' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,881 : WARNING : duplicate word '634' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,882 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,882 : WARNING : duplicate word '682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,883 : WARNING : duplicate word '4913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,884 : WARNING : duplicate word '16' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,884 : WARNING : duplicate word '62' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,885 : WARNING : duplicate word '2343' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,886 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,887 : WARNING : duplicate word '4641' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,888 : WARNING : duplicate word '554' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,889 : WARNING : duplicate word '576' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,890 : WARNING : duplicate word '085' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,891 : WARNING : duplicate word '055' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:26,892 : WARNING : duplicate word '649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,892 : WARNING : duplicate word '072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,893 : WARNING : duplicate word '53' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,894 : WARNING : duplicate word '213' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,894 : WARNING : duplicate word '881' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,895 : WARNING : duplicate word '329' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,896 : WARNING : duplicate word '902' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,896 : WARNING : duplicate word '2145' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,897 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,897 : WARNING : duplicate word '926' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,898 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,899 : WARNING : duplicate word '588' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,899 : WARNING : duplicate word '379' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,900 : WARNING : duplicate word '0023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,900 : WARNING : duplicate word '968' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,901 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,901 : WARNING : duplicate word '036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,902 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,902 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,903 : WARNING : duplicate word '654' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,903 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,906 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,907 : WARNING : duplicate word '6144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,908 : WARNING : duplicate word '7573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,908 : WARNING : duplicate word '4971' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,909 : WARNING : duplicate word '851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,910 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,912 : WARNING : duplicate word '901' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,914 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,915 : WARNING : duplicate word '4508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,917 : WARNING : duplicate word '207' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,918 : WARNING : duplicate word '132' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,919 : WARNING : duplicate word '6105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,920 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,921 : WARNING : duplicate word '195' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,922 : WARNING : duplicate word '074' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,923 : WARNING : duplicate word '001' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,924 : WARNING : duplicate word '4321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,925 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,926 : WARNING : duplicate word '5916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,927 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,928 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,929 : WARNING : duplicate word '076' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,929 : WARNING : duplicate word '667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,930 : WARNING : duplicate word '821' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,931 : WARNING : duplicate word '963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,932 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,934 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,935 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,937 : WARNING : duplicate word '689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,943 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,944 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,944 : WARNING : duplicate word '939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,946 : WARNING : duplicate word '822' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,947 : WARNING : duplicate word '6626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,947 : WARNING : duplicate word '052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,949 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,950 : WARNING : duplicate word '803' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,951 : WARNING : duplicate word '7352' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,952 : WARNING : duplicate word '203' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,953 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,954 : WARNING : duplicate word '9008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,955 : WARNING : duplicate word '181' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,956 : WARNING : duplicate word '334' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,956 : WARNING : duplicate word '795' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,957 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:26,957 : WARNING : duplicate word '773' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,001 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,002 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,003 : WARNING : duplicate word '407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,004 : WARNING : duplicate word '493' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,006 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,007 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,007 : WARNING : duplicate word '802' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,009 : WARNING : duplicate word '955' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,009 : WARNING : duplicate word '023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,012 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,014 : WARNING : duplicate word '428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,015 : WARNING : duplicate word '012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,016 : WARNING : duplicate word '694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,023 : WARNING : duplicate word '1052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,025 : WARNING : duplicate word '148' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,026 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,027 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,030 : WARNING : duplicate word '296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,031 : WARNING : duplicate word '538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,033 : WARNING : duplicate word '105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,034 : WARNING : duplicate word '449' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,035 : WARNING : duplicate word '184' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,036 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,038 : WARNING : duplicate word '5972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,039 : WARNING : duplicate word '2413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,040 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,041 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,042 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,043 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,044 : WARNING : duplicate word '295' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,047 : WARNING : duplicate word '6847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,048 : WARNING : duplicate word '5782' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,049 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,050 : WARNING : duplicate word '171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,051 : WARNING : duplicate word '8811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,051 : WARNING : duplicate word '2665' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,052 : WARNING : duplicate word '98' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,053 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,054 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,057 : WARNING : duplicate word '2413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,058 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,058 : WARNING : duplicate word '344' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,059 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,060 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,061 : WARNING : duplicate word '534' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,062 : WARNING : duplicate word '3402' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,062 : WARNING : duplicate word '397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,064 : WARNING : duplicate word '9073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,064 : WARNING : duplicate word '501' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,065 : WARNING : duplicate word '9282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,065 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,066 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,067 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,068 : WARNING : duplicate word '689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,069 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,070 : WARNING : duplicate word '15019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,072 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,073 : WARNING : duplicate word '804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,074 : WARNING : duplicate word '393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,075 : WARNING : duplicate word '166' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,076 : WARNING : duplicate word '2356' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,080 : WARNING : duplicate word '656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,083 : WARNING : duplicate word '225' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,084 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,085 : WARNING : duplicate word '054' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,086 : WARNING : duplicate word '877' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,086 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,087 : WARNING : duplicate word '379' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,090 : WARNING : duplicate word '792' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,090 : WARNING : duplicate word '617' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,091 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,092 : WARNING : duplicate word '2' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,093 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,094 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,094 : WARNING : duplicate word '226' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,095 : WARNING : duplicate word '687' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,095 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,096 : WARNING : duplicate word '439' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,096 : WARNING : duplicate word '3746' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,097 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,097 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,098 : WARNING : duplicate word '082' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,098 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,099 : WARNING : duplicate word '043' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,100 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,100 : WARNING : duplicate word '8023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,101 : WARNING : duplicate word '8312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,101 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,102 : WARNING : duplicate word '603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,103 : WARNING : duplicate word '881' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,103 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,104 : WARNING : duplicate word '055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,105 : WARNING : duplicate word '9929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,106 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,109 : WARNING : duplicate word '495' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,112 : WARNING : duplicate word '162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,113 : WARNING : duplicate word '35' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,115 : WARNING : duplicate word '332' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,117 : WARNING : duplicate word '894' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,118 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,119 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,120 : WARNING : duplicate word '773' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,121 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,122 : WARNING : duplicate word '038' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,123 : WARNING : duplicate word '331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,124 : WARNING : duplicate word '749' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,129 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,130 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,131 : WARNING : duplicate word '3718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,132 : WARNING : duplicate word '6498' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,133 : WARNING : duplicate word '776' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,134 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,137 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,139 : WARNING : duplicate word '2838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,140 : WARNING : duplicate word '904' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,141 : WARNING : duplicate word '755' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,142 : WARNING : duplicate word '3716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,143 : WARNING : duplicate word '4161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,143 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,144 : WARNING : duplicate word '516' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,145 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,147 : WARNING : duplicate word '1667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,148 : WARNING : duplicate word '932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,150 : WARNING : duplicate word '004' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,151 : WARNING : duplicate word '2055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,152 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,153 : WARNING : duplicate word '9444' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,155 : WARNING : duplicate word '9601' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,156 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,157 : WARNING : duplicate word '836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,158 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,159 : WARNING : duplicate word '141' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,160 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,162 : WARNING : duplicate word '106' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,162 : WARNING : duplicate word '2417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,164 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,165 : WARNING : duplicate word '074' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,166 : WARNING : duplicate word '567' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,167 : WARNING : duplicate word '276' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,168 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,168 : WARNING : duplicate word '071' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,169 : WARNING : duplicate word '195' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,170 : WARNING : duplicate word '444' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,171 : WARNING : duplicate word '162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,172 : WARNING : duplicate word '1423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,173 : WARNING : duplicate word '774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,177 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,179 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,180 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,181 : WARNING : duplicate word '0476' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,182 : WARNING : duplicate word '7128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,182 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,183 : WARNING : duplicate word '1322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,184 : WARNING : duplicate word '979' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,185 : WARNING : duplicate word '963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,185 : WARNING : duplicate word '819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,186 : WARNING : duplicate word '421' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,187 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,190 : WARNING : duplicate word '3951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,191 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,192 : WARNING : duplicate word '29' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,193 : WARNING : duplicate word '7063' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,194 : WARNING : duplicate word '675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,195 : WARNING : duplicate word '791' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,197 : WARNING : duplicate word '822' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,199 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,200 : WARNING : duplicate word '8496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,201 : WARNING : duplicate word '535' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,202 : WARNING : duplicate word '715' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,203 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,205 : WARNING : duplicate word '877' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,206 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,207 : WARNING : duplicate word '492' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,208 : WARNING : duplicate word '437' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,209 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,210 : WARNING : duplicate word '164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,210 : WARNING : duplicate word '075' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,212 : WARNING : duplicate word '774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,213 : WARNING : duplicate word '741' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,213 : WARNING : duplicate word '1739' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,214 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,215 : WARNING : duplicate word '8159' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,216 : WARNING : duplicate word '73' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,217 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,218 : WARNING : duplicate word '047' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,218 : WARNING : duplicate word '8937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,219 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,220 : WARNING : duplicate word '213' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,222 : WARNING : duplicate word '238' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,223 : WARNING : duplicate word '9774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,224 : WARNING : duplicate word '4993' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,225 : WARNING : duplicate word '2611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,229 : WARNING : duplicate word '441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,230 : WARNING : duplicate word '036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,231 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,231 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,232 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,233 : WARNING : duplicate word '405' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,233 : WARNING : duplicate word '012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,270 : WARNING : duplicate word '8729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,273 : WARNING : duplicate word '387' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,274 : WARNING : duplicate word '4105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,274 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,275 : WARNING : duplicate word '2662' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,276 : WARNING : duplicate word '936' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,277 : WARNING : duplicate word '794' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,278 : WARNING : duplicate word '1999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,280 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,282 : WARNING : duplicate word '322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,283 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,285 : WARNING : duplicate word '2182' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,286 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,287 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,288 : WARNING : duplicate word '426' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,289 : WARNING : duplicate word '6551' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,290 : WARNING : duplicate word '492' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,293 : WARNING : duplicate word '235' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,294 : WARNING : duplicate word '222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,297 : WARNING : duplicate word '075' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,298 : WARNING : duplicate word '3322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,299 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,300 : WARNING : duplicate word '4566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,301 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,302 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,303 : WARNING : duplicate word '804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,303 : WARNING : duplicate word '658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,305 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,305 : WARNING : duplicate word '693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,306 : WARNING : duplicate word '9634' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,307 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,308 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,309 : WARNING : duplicate word '6753' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,310 : WARNING : duplicate word '9963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,311 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,313 : WARNING : duplicate word '427' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,314 : WARNING : duplicate word '0656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,318 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,319 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,320 : WARNING : duplicate word '912' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,322 : WARNING : duplicate word '959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,326 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,333 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,334 : WARNING : duplicate word '158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,335 : WARNING : duplicate word '754' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,337 : WARNING : duplicate word '459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,338 : WARNING : duplicate word '0045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,340 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,341 : WARNING : duplicate word '962' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,342 : WARNING : duplicate word '414' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,343 : WARNING : duplicate word '067' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,344 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,346 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,347 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,348 : WARNING : duplicate word '404' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,349 : WARNING : duplicate word '278' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,351 : WARNING : duplicate word '499' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,352 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,356 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,358 : WARNING : duplicate word '7719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,359 : WARNING : duplicate word '4196' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,360 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,362 : WARNING : duplicate word '845' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,363 : WARNING : duplicate word '1053' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,364 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,365 : WARNING : duplicate word '568' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,367 : WARNING : duplicate word '212' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,368 : WARNING : duplicate word '588' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,369 : WARNING : duplicate word '5671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,370 : WARNING : duplicate word '8811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,374 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,375 : WARNING : duplicate word '6389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,376 : WARNING : duplicate word '384' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,377 : WARNING : duplicate word '331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,381 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,389 : WARNING : duplicate word '415' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,390 : WARNING : duplicate word '052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,391 : WARNING : duplicate word '9745' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,395 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,396 : WARNING : duplicate word '96' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,397 : WARNING : duplicate word '444' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,399 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,400 : WARNING : duplicate word '2687' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,402 : WARNING : duplicate word '826' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,403 : WARNING : duplicate word '3431' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,404 : WARNING : duplicate word '041' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,406 : WARNING : duplicate word '0548' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,407 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,408 : WARNING : duplicate word '495' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,409 : WARNING : duplicate word '033' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,410 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,411 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,412 : WARNING : duplicate word '734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,413 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,415 : WARNING : duplicate word '579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,417 : WARNING : duplicate word '691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,419 : WARNING : duplicate word '714' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,420 : WARNING : duplicate word '7436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,423 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,425 : WARNING : duplicate word '529' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,426 : WARNING : duplicate word '836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,427 : WARNING : duplicate word '322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,435 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,437 : WARNING : duplicate word '348' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,439 : WARNING : duplicate word '719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,440 : WARNING : duplicate word '509' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,443 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,443 : WARNING : duplicate word '013' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,445 : WARNING : duplicate word '9942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,446 : WARNING : duplicate word '259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,448 : WARNING : duplicate word '331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,450 : WARNING : duplicate word '458' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,451 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,453 : WARNING : duplicate word '8994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,454 : WARNING : duplicate word '147' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,455 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,457 : WARNING : duplicate word '487' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,457 : WARNING : duplicate word '265' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,458 : WARNING : duplicate word '984' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,460 : WARNING : duplicate word '058' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,462 : WARNING : duplicate word '8729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,463 : WARNING : duplicate word '531' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,464 : WARNING : duplicate word '972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,467 : WARNING : duplicate word '504' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,468 : WARNING : duplicate word '358' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,471 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,475 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,478 : WARNING : duplicate word '3571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,479 : WARNING : duplicate word '9658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,481 : WARNING : duplicate word '243' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,482 : WARNING : duplicate word '239' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,484 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,485 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,486 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,489 : WARNING : duplicate word '816' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,490 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,492 : WARNING : duplicate word '601' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,493 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,494 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,495 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,497 : WARNING : duplicate word '694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,499 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,500 : WARNING : duplicate word '021' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,502 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,504 : WARNING : duplicate word '214' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,506 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,507 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,510 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,511 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,515 : WARNING : duplicate word '173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,516 : WARNING : duplicate word '1009' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,521 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,522 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,523 : WARNING : duplicate word '866' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,524 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,525 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,528 : WARNING : duplicate word '6701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,529 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,530 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,531 : WARNING : duplicate word '548' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,532 : WARNING : duplicate word '95' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,533 : WARNING : duplicate word '074' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,535 : WARNING : duplicate word '3219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,537 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,539 : WARNING : duplicate word '612' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,541 : WARNING : duplicate word '611' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,542 : WARNING : duplicate word '0062' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,543 : WARNING : duplicate word '5689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,548 : WARNING : duplicate word '702' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,550 : WARNING : duplicate word '233' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,555 : WARNING : duplicate word '916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,557 : WARNING : duplicate word '244' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,558 : WARNING : duplicate word '5571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,560 : WARNING : duplicate word '863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,561 : WARNING : duplicate word '756' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,563 : WARNING : duplicate word '5108' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,564 : WARNING : duplicate word '827' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,565 : WARNING : duplicate word '6825' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,567 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,568 : WARNING : duplicate word '8116' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,571 : WARNING : duplicate word '333' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,572 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,573 : WARNING : duplicate word '9335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,574 : WARNING : duplicate word '5419' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,575 : WARNING : duplicate word '432' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,578 : WARNING : duplicate word '897' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,580 : WARNING : duplicate word '881' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,582 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,583 : WARNING : duplicate word '725' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,584 : WARNING : duplicate word '625' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,585 : WARNING : duplicate word '293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,586 : WARNING : duplicate word '6464' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,589 : WARNING : duplicate word '356' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,590 : WARNING : duplicate word '448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,591 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,596 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,598 : WARNING : duplicate word '706' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,598 : WARNING : duplicate word '8807' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,601 : WARNING : duplicate word '4145' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,602 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,625 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,626 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,627 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,629 : WARNING : duplicate word '981' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,631 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,632 : WARNING : duplicate word '367' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,634 : WARNING : duplicate word '166' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,637 : WARNING : duplicate word '031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,642 : WARNING : duplicate word '007' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,643 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,644 : WARNING : duplicate word '405' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,646 : WARNING : duplicate word '147' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,647 : WARNING : duplicate word '5035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,648 : WARNING : duplicate word '6835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,649 : WARNING : duplicate word '7469' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,652 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,653 : WARNING : duplicate word '7547' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,654 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,655 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,656 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,657 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,658 : WARNING : duplicate word '0003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,659 : WARNING : duplicate word '7039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,660 : WARNING : duplicate word '052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,662 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,663 : WARNING : duplicate word '0142' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,664 : WARNING : duplicate word '9472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,665 : WARNING : duplicate word '412' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,667 : WARNING : duplicate word '4306' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,668 : WARNING : duplicate word '0277' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,669 : WARNING : duplicate word '183' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,670 : WARNING : duplicate word '5022' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,671 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,673 : WARNING : duplicate word '956' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,674 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,676 : WARNING : duplicate word '195' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,677 : WARNING : duplicate word '4934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,678 : WARNING : duplicate word '988' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,679 : WARNING : duplicate word '5152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,680 : WARNING : duplicate word '705' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,683 : WARNING : duplicate word '579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,684 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,685 : WARNING : duplicate word '023' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,686 : WARNING : duplicate word '9404' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,687 : WARNING : duplicate word '88' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,689 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,691 : WARNING : duplicate word '842' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,692 : WARNING : duplicate word '053' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,693 : WARNING : duplicate word '184' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,695 : WARNING : duplicate word '2966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,696 : WARNING : duplicate word '915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,697 : WARNING : duplicate word '569' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,698 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,698 : WARNING : duplicate word '3878' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,699 : WARNING : duplicate word '593' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,703 : WARNING : duplicate word '456' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,706 : WARNING : duplicate word '122' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,707 : WARNING : duplicate word '404' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,710 : WARNING : duplicate word '5328' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,712 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,714 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,715 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,718 : WARNING : duplicate word '512' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,719 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,722 : WARNING : duplicate word '424' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,724 : WARNING : duplicate word '0921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,726 : WARNING : duplicate word '447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,727 : WARNING : duplicate word '174' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,728 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,730 : WARNING : duplicate word '279' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,732 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,734 : WARNING : duplicate word '481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,737 : WARNING : duplicate word '801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,740 : WARNING : duplicate word '746' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,741 : WARNING : duplicate word '802' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,742 : WARNING : duplicate word '442' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,743 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,744 : WARNING : duplicate word '211' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,748 : WARNING : duplicate word '2846' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,751 : WARNING : duplicate word '257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,752 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,753 : WARNING : duplicate word '799' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,754 : WARNING : duplicate word '1063' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,755 : WARNING : duplicate word '482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,756 : WARNING : duplicate word '236' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,757 : WARNING : duplicate word '321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,758 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,759 : WARNING : duplicate word '9077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,760 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,761 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,762 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,763 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,764 : WARNING : duplicate word '399' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,765 : WARNING : duplicate word '058' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,766 : WARNING : duplicate word '7389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,769 : WARNING : duplicate word '4206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,770 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,772 : WARNING : duplicate word '31' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,773 : WARNING : duplicate word '3253' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,774 : WARNING : duplicate word '1242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,775 : WARNING : duplicate word '0969' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,780 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,782 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,783 : WARNING : duplicate word '7793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,784 : WARNING : duplicate word '094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,785 : WARNING : duplicate word '3784' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,786 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,787 : WARNING : duplicate word '416' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,789 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,791 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,792 : WARNING : duplicate word '783' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,793 : WARNING : duplicate word '7428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,795 : WARNING : duplicate word '0517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,798 : WARNING : duplicate word '296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,799 : WARNING : duplicate word '498' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,802 : WARNING : duplicate word '316' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,803 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,804 : WARNING : duplicate word '511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,805 : WARNING : duplicate word '222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,806 : WARNING : duplicate word '059' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,807 : WARNING : duplicate word '1144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,808 : WARNING : duplicate word '4915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,809 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,810 : WARNING : duplicate word '1029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,811 : WARNING : duplicate word '954' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,812 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,813 : WARNING : duplicate word '0732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,814 : WARNING : duplicate word '825' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,814 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,815 : WARNING : duplicate word '53' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,816 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,818 : WARNING : duplicate word '333' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,819 : WARNING : duplicate word '8557' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,820 : WARNING : duplicate word '272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,820 : WARNING : duplicate word '624' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,822 : WARNING : duplicate word '4735' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,823 : WARNING : duplicate word '9204' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,824 : WARNING : duplicate word '62' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,826 : WARNING : duplicate word '0105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,827 : WARNING : duplicate word '388' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,828 : WARNING : duplicate word '3793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,833 : WARNING : duplicate word '077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,840 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,846 : WARNING : duplicate word '201' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,848 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,853 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,855 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,856 : WARNING : duplicate word '647' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,858 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,859 : WARNING : duplicate word '8293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,860 : WARNING : duplicate word '1359' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,863 : WARNING : duplicate word '6717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,865 : WARNING : duplicate word '158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,867 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,869 : WARNING : duplicate word '751' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,870 : WARNING : duplicate word '456' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,870 : WARNING : duplicate word '753' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,872 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,876 : WARNING : duplicate word '8675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,882 : WARNING : duplicate word '093' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,885 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,886 : WARNING : duplicate word '976' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,887 : WARNING : duplicate word '842' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,889 : WARNING : duplicate word '275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,890 : WARNING : duplicate word '049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,891 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,892 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,893 : WARNING : duplicate word '2639' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,895 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,898 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,899 : WARNING : duplicate word '816' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,900 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,901 : WARNING : duplicate word '2089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,902 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,904 : WARNING : duplicate word '5236' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,905 : WARNING : duplicate word '756' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,907 : WARNING : duplicate word '268' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,909 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,914 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,915 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,917 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,921 : WARNING : duplicate word '074' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:27,924 : WARNING : duplicate word '689' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,926 : WARNING : duplicate word '88' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,927 : WARNING : duplicate word '798' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,932 : WARNING : duplicate word '0767' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,934 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,935 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,936 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,937 : WARNING : duplicate word '399' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,938 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,941 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,942 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,944 : WARNING : duplicate word '0769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,945 : WARNING : duplicate word '413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,948 : WARNING : duplicate word '604' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,949 : WARNING : duplicate word '7055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,950 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,951 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,983 : WARNING : duplicate word '7102' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,984 : WARNING : duplicate word '603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,985 : WARNING : duplicate word '284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,987 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,988 : WARNING : duplicate word '61' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,989 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,993 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,995 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,998 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:27,999 : WARNING : duplicate word '93' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,001 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,002 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,003 : WARNING : duplicate word '941' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,004 : WARNING : duplicate word '897' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,005 : WARNING : duplicate word '414' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,007 : WARNING : duplicate word '9374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,008 : WARNING : duplicate word '502' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,009 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,011 : WARNING : duplicate word '305' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,015 : WARNING : duplicate word '708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,016 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,018 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,019 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,020 : WARNING : duplicate word '676' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,020 : WARNING : duplicate word '459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,021 : WARNING : duplicate word '626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,022 : WARNING : duplicate word '7659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,023 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,024 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,028 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,029 : WARNING : duplicate word '404' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,034 : WARNING : duplicate word '9136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,036 : WARNING : duplicate word '2012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,037 : WARNING : duplicate word '707' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,038 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,040 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,041 : WARNING : duplicate word '497' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,043 : WARNING : duplicate word '2193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,043 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,050 : WARNING : duplicate word '9037' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,053 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,055 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,056 : WARNING : duplicate word '9445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,057 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,057 : WARNING : duplicate word '904' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,059 : WARNING : duplicate word '906' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,064 : WARNING : duplicate word '489' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,067 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,070 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,073 : WARNING : duplicate word '611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,075 : WARNING : duplicate word '804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,077 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,078 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,079 : WARNING : duplicate word '8371' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,080 : WARNING : duplicate word '4684' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,082 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,083 : WARNING : duplicate word '775' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,084 : WARNING : duplicate word '0224' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,085 : WARNING : duplicate word '3878' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,086 : WARNING : duplicate word '7875' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,087 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,091 : WARNING : duplicate word '0272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,092 : WARNING : duplicate word '119' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,097 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,101 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,102 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,107 : WARNING : duplicate word '834' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,108 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,109 : WARNING : duplicate word '499' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,110 : WARNING : duplicate word '6671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,115 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,116 : WARNING : duplicate word '241' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,122 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,122 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,123 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,125 : WARNING : duplicate word '446' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,126 : WARNING : duplicate word '472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,127 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,127 : WARNING : duplicate word '351' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,129 : WARNING : duplicate word '262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,129 : WARNING : duplicate word '741' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,130 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,131 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,133 : WARNING : duplicate word '8397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,134 : WARNING : duplicate word '927' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,135 : WARNING : duplicate word '243' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,136 : WARNING : duplicate word '463' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,136 : WARNING : duplicate word '207' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,137 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,138 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,139 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,140 : WARNING : duplicate word '3021' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,141 : WARNING : duplicate word '0651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,141 : WARNING : duplicate word '181' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,142 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,142 : WARNING : duplicate word '493' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,143 : WARNING : duplicate word '4306' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,143 : WARNING : duplicate word '336' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,144 : WARNING : duplicate word '001' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,145 : WARNING : duplicate word '598' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,148 : WARNING : duplicate word '876' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,148 : WARNING : duplicate word '424' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,149 : WARNING : duplicate word '2992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,150 : WARNING : duplicate word '373' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,150 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,151 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,151 : WARNING : duplicate word '3539' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,152 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,153 : WARNING : duplicate word '486' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,155 : WARNING : duplicate word '412' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,155 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,156 : WARNING : duplicate word '1664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,157 : WARNING : duplicate word '6418' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,157 : WARNING : duplicate word '641' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,164 : WARNING : duplicate word '7005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,165 : WARNING : duplicate word '722' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,166 : WARNING : duplicate word '691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,167 : WARNING : duplicate word '6596' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,170 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,172 : WARNING : duplicate word '73' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,173 : WARNING : duplicate word '105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,174 : WARNING : duplicate word '142' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,177 : WARNING : duplicate word '048' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,179 : WARNING : duplicate word '302' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,181 : WARNING : duplicate word '1994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,183 : WARNING : duplicate word '362' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,184 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,185 : WARNING : duplicate word '6835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,186 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,186 : WARNING : duplicate word '5177' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,187 : WARNING : duplicate word '14' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,190 : WARNING : duplicate word '224' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,191 : WARNING : duplicate word '898' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,192 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,193 : WARNING : duplicate word '5915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,194 : WARNING : duplicate word '3657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,195 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,197 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,199 : WARNING : duplicate word '952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,201 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,202 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,203 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,206 : WARNING : duplicate word '785' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,207 : WARNING : duplicate word '956' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,209 : WARNING : duplicate word '5644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,210 : WARNING : duplicate word '58' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,212 : WARNING : duplicate word '078' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,213 : WARNING : duplicate word '195' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,214 : WARNING : duplicate word '697' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,215 : WARNING : duplicate word '878' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,216 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,217 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,218 : WARNING : duplicate word '858' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,220 : WARNING : duplicate word '788' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,221 : WARNING : duplicate word '774' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,223 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,229 : WARNING : duplicate word '521' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,231 : WARNING : duplicate word '453' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,234 : WARNING : duplicate word '485' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,235 : WARNING : duplicate word '0538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,237 : WARNING : duplicate word '537' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,238 : WARNING : duplicate word '574' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,240 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,242 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,243 : WARNING : duplicate word '814' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,244 : WARNING : duplicate word '3651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,246 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,247 : WARNING : duplicate word '4402' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,248 : WARNING : duplicate word '0804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,249 : WARNING : duplicate word '891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,250 : WARNING : duplicate word '547' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,251 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,252 : WARNING : duplicate word '373' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,257 : WARNING : duplicate word '3074' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,261 : WARNING : duplicate word '315' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,263 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,264 : WARNING : duplicate word '7001' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,268 : WARNING : duplicate word '848' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,270 : WARNING : duplicate word '7162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,270 : WARNING : duplicate word '671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,271 : WARNING : duplicate word '413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,273 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,275 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,277 : WARNING : duplicate word '0124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,277 : WARNING : duplicate word '1792' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,279 : WARNING : duplicate word '625' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,281 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,285 : WARNING : duplicate word '34' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,287 : WARNING : duplicate word '089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,288 : WARNING : duplicate word '599' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,289 : WARNING : duplicate word '555' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,291 : WARNING : duplicate word '184' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,292 : WARNING : duplicate word '068' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,295 : WARNING : duplicate word '6449' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,296 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,297 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,299 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,300 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,301 : WARNING : duplicate word '3222' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,339 : WARNING : duplicate word '362' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,341 : WARNING : duplicate word '162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,341 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,342 : WARNING : duplicate word '808' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,343 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,347 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,348 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,349 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,350 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,351 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,352 : WARNING : duplicate word '318' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,353 : WARNING : duplicate word '7941' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,354 : WARNING : duplicate word '721' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,355 : WARNING : duplicate word '3963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,356 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,356 : WARNING : duplicate word '3222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,357 : WARNING : duplicate word '0071' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,358 : WARNING : duplicate word '348' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,359 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,360 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,361 : WARNING : duplicate word '1718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,362 : WARNING : duplicate word '488' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,363 : WARNING : duplicate word '23' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,364 : WARNING : duplicate word '9282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,365 : WARNING : duplicate word '971' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,371 : WARNING : duplicate word '064' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,374 : WARNING : duplicate word '168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,375 : WARNING : duplicate word '5686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,375 : WARNING : duplicate word '526' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,376 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,377 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,378 : WARNING : duplicate word '262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,379 : WARNING : duplicate word '214' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,380 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,381 : WARNING : duplicate word '064' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,382 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,383 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,384 : WARNING : duplicate word '525' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,385 : WARNING : duplicate word '851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,386 : WARNING : duplicate word '675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,387 : WARNING : duplicate word '344' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,388 : WARNING : duplicate word '284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,388 : WARNING : duplicate word '08' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,389 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,391 : WARNING : duplicate word '7975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,392 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,394 : WARNING : duplicate word '4159' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,395 : WARNING : duplicate word '4793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,396 : WARNING : duplicate word '6396' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,397 : WARNING : duplicate word '334' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,398 : WARNING : duplicate word '3596' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,399 : WARNING : duplicate word '865' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,400 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,401 : WARNING : duplicate word '448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,402 : WARNING : duplicate word '8906' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,403 : WARNING : duplicate word '0581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,404 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,405 : WARNING : duplicate word '0612' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,407 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,408 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,409 : WARNING : duplicate word '362' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,410 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,415 : WARNING : duplicate word '9252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,416 : WARNING : duplicate word '229' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,417 : WARNING : duplicate word '237' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,418 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,419 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,420 : WARNING : duplicate word '8366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,421 : WARNING : duplicate word '134' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,423 : WARNING : duplicate word '7725' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,424 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,424 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,425 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,426 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,427 : WARNING : duplicate word '029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,429 : WARNING : duplicate word '141' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,430 : WARNING : duplicate word '949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,431 : WARNING : duplicate word '515' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,431 : WARNING : duplicate word '952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,432 : WARNING : duplicate word '473' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,433 : WARNING : duplicate word '881' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,434 : WARNING : duplicate word '5651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,435 : WARNING : duplicate word '88' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,435 : WARNING : duplicate word '308' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,436 : WARNING : duplicate word '6171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,437 : WARNING : duplicate word '032' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,438 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,441 : WARNING : duplicate word '0891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,443 : WARNING : duplicate word '4595' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,445 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,446 : WARNING : duplicate word '844' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,447 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,448 : WARNING : duplicate word '048' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,448 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,449 : WARNING : duplicate word '427' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,450 : WARNING : duplicate word '607' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,450 : WARNING : duplicate word '1685' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,451 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,452 : WARNING : duplicate word '899' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,452 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,453 : WARNING : duplicate word '939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,454 : WARNING : duplicate word '932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,454 : WARNING : duplicate word '06' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,456 : WARNING : duplicate word '8379' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,457 : WARNING : duplicate word '0856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,457 : WARNING : duplicate word '898' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,458 : WARNING : duplicate word '857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,458 : WARNING : duplicate word '286' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,459 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,460 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,460 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,462 : WARNING : duplicate word '055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,467 : WARNING : duplicate word '8867' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,468 : WARNING : duplicate word '7508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,470 : WARNING : duplicate word '154' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,471 : WARNING : duplicate word '443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,472 : WARNING : duplicate word '504' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,473 : WARNING : duplicate word '486' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,474 : WARNING : duplicate word '0447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,474 : WARNING : duplicate word '614' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,475 : WARNING : duplicate word '613' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,475 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,476 : WARNING : duplicate word '366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,476 : WARNING : duplicate word '4' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,477 : WARNING : duplicate word '2589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,478 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,479 : WARNING : duplicate word '629' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,481 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,482 : WARNING : duplicate word '3924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,483 : WARNING : duplicate word '309' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,484 : WARNING : duplicate word '9871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,485 : WARNING : duplicate word '158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,485 : WARNING : duplicate word '512' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,486 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,487 : WARNING : duplicate word '372' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,487 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,488 : WARNING : duplicate word '1475' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,489 : WARNING : duplicate word '555' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,489 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,490 : WARNING : duplicate word '7377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,491 : WARNING : duplicate word '1556' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,491 : WARNING : duplicate word '199' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,492 : WARNING : duplicate word '576' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,492 : WARNING : duplicate word '272' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,493 : WARNING : duplicate word '441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,494 : WARNING : duplicate word '149' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,495 : WARNING : duplicate word '62' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,495 : WARNING : duplicate word '174' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,496 : WARNING : duplicate word '642' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,496 : WARNING : duplicate word '9193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,497 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,498 : WARNING : duplicate word '73' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,498 : WARNING : duplicate word '441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,499 : WARNING : duplicate word '192' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,500 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,500 : WARNING : duplicate word '84' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,501 : WARNING : duplicate word '764' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,501 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,502 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,502 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,503 : WARNING : duplicate word '4617' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,503 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,504 : WARNING : duplicate word '72' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,504 : WARNING : duplicate word '5815' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,505 : WARNING : duplicate word '903' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,505 : WARNING : duplicate word '905' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,506 : WARNING : duplicate word '678' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,507 : WARNING : duplicate word '486' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,507 : WARNING : duplicate word '713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,508 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,508 : WARNING : duplicate word '0603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,509 : WARNING : duplicate word '653' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,509 : WARNING : duplicate word '353' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,510 : WARNING : duplicate word '347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,510 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,514 : WARNING : duplicate word '2708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,515 : WARNING : duplicate word '221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,516 : WARNING : duplicate word '9563' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,517 : WARNING : duplicate word '595' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,517 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,518 : WARNING : duplicate word '2939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,518 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,519 : WARNING : duplicate word '956' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,519 : WARNING : duplicate word '542' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,520 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,520 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,521 : WARNING : duplicate word '937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,522 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,523 : WARNING : duplicate word '668' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,524 : WARNING : duplicate word '564' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,525 : WARNING : duplicate word '4196' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,526 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,526 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,529 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,530 : WARNING : duplicate word '488' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,531 : WARNING : duplicate word '969' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,533 : WARNING : duplicate word '631' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,534 : WARNING : duplicate word '7189' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,535 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,537 : WARNING : duplicate word '163' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,573 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,574 : WARNING : duplicate word '785' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,575 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,576 : WARNING : duplicate word '6906' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,577 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,578 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,579 : WARNING : duplicate word '834' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,580 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,581 : WARNING : duplicate word '789' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,582 : WARNING : duplicate word '125' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,583 : WARNING : duplicate word '319' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,583 : WARNING : duplicate word '114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,584 : WARNING : duplicate word '111' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,585 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,586 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,586 : WARNING : duplicate word '873' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,587 : WARNING : duplicate word '6396' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,588 : WARNING : duplicate word '158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,589 : WARNING : duplicate word '693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,590 : WARNING : duplicate word '68' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,591 : WARNING : duplicate word '1575' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,592 : WARNING : duplicate word '147' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,593 : WARNING : duplicate word '611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,593 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,595 : WARNING : duplicate word '888' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,597 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,597 : WARNING : duplicate word '631' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,598 : WARNING : duplicate word '763' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,599 : WARNING : duplicate word '074' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,599 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,600 : WARNING : duplicate word '788' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,601 : WARNING : duplicate word '8713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,602 : WARNING : duplicate word '356' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,602 : WARNING : duplicate word '5104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,603 : WARNING : duplicate word '9831' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,604 : WARNING : duplicate word '4636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,604 : WARNING : duplicate word '638' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,607 : WARNING : duplicate word '7055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,608 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,608 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,609 : WARNING : duplicate word '924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,610 : WARNING : duplicate word '866' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,613 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,615 : WARNING : duplicate word '301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,616 : WARNING : duplicate word '466' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,618 : WARNING : duplicate word '9818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,619 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,620 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,621 : WARNING : duplicate word '9519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,622 : WARNING : duplicate word '551' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,623 : WARNING : duplicate word '657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,624 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,625 : WARNING : duplicate word '3431' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,626 : WARNING : duplicate word '094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,627 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,628 : WARNING : duplicate word '8461' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,629 : WARNING : duplicate word '374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,631 : WARNING : duplicate word '3038' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,632 : WARNING : duplicate word '8967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,633 : WARNING : duplicate word '838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,634 : WARNING : duplicate word '7732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,635 : WARNING : duplicate word '6464' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,636 : WARNING : duplicate word '4487' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,636 : WARNING : duplicate word '754' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,637 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,637 : WARNING : duplicate word '1836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,638 : WARNING : duplicate word '178' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,639 : WARNING : duplicate word '8397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,640 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,641 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,641 : WARNING : duplicate word '045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,642 : WARNING : duplicate word '4304' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,643 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,643 : WARNING : duplicate word '454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,644 : WARNING : duplicate word '6057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,644 : WARNING : duplicate word '483' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,646 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,647 : WARNING : duplicate word '2989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,648 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,649 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,650 : WARNING : duplicate word '504' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,651 : WARNING : duplicate word '763' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,654 : WARNING : duplicate word '8933' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,656 : WARNING : duplicate word '565' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,657 : WARNING : duplicate word '043' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,658 : WARNING : duplicate word '852' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,659 : WARNING : duplicate word '1544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,660 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,661 : WARNING : duplicate word '4939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,663 : WARNING : duplicate word '824' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,663 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,665 : WARNING : duplicate word '4498' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,666 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,667 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,668 : WARNING : duplicate word '059' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,669 : WARNING : duplicate word '878' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,670 : WARNING : duplicate word '108' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,671 : WARNING : duplicate word '547' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,672 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,673 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,674 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,675 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,676 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,677 : WARNING : duplicate word '114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,679 : WARNING : duplicate word '8027' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,680 : WARNING : duplicate word '517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,681 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,682 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,683 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,683 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,684 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,685 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,685 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,686 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,687 : WARNING : duplicate word '381' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,687 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,688 : WARNING : duplicate word '854' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,690 : WARNING : duplicate word '3886' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,691 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,693 : WARNING : duplicate word '398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,699 : WARNING : duplicate word '684' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,700 : WARNING : duplicate word '3082' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,702 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,703 : WARNING : duplicate word '616' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,706 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,706 : WARNING : duplicate word '244' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,707 : WARNING : duplicate word '755' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,708 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,710 : WARNING : duplicate word '852' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,712 : WARNING : duplicate word '054' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,713 : WARNING : duplicate word '736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,714 : WARNING : duplicate word '814' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,715 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,716 : WARNING : duplicate word '177' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,717 : WARNING : duplicate word '2561' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,719 : WARNING : duplicate word '475' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,720 : WARNING : duplicate word '589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,721 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,722 : WARNING : duplicate word '09' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,723 : WARNING : duplicate word '0796' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,723 : WARNING : duplicate word '9323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,725 : WARNING : duplicate word '0327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,728 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,732 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,735 : WARNING : duplicate word '137' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,736 : WARNING : duplicate word '365' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,737 : WARNING : duplicate word '7203' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,737 : WARNING : duplicate word '947' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,739 : WARNING : duplicate word '6851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,741 : WARNING : duplicate word '2252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,742 : WARNING : duplicate word '342' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,743 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,743 : WARNING : duplicate word '442' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,744 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,747 : WARNING : duplicate word '498' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,748 : WARNING : duplicate word '517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,749 : WARNING : duplicate word '064' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,750 : WARNING : duplicate word '6941' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,752 : WARNING : duplicate word '045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,753 : WARNING : duplicate word '5134' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,755 : WARNING : duplicate word '286' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,756 : WARNING : duplicate word '065' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,757 : WARNING : duplicate word '365' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,758 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,759 : WARNING : duplicate word '007' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,760 : WARNING : duplicate word '0752' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,763 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,764 : WARNING : duplicate word '643' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,764 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,765 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,766 : WARNING : duplicate word '3873' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,772 : WARNING : duplicate word '429' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,773 : WARNING : duplicate word '694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,775 : WARNING : duplicate word '066' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,778 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,778 : WARNING : duplicate word '1284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,779 : WARNING : duplicate word '303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,780 : WARNING : duplicate word '894' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,780 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,781 : WARNING : duplicate word '8811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,782 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,783 : WARNING : duplicate word '439' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,784 : WARNING : duplicate word '2835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,785 : WARNING : duplicate word '143' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,785 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,786 : WARNING : duplicate word '537' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,787 : WARNING : duplicate word '324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,788 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,792 : WARNING : duplicate word '287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,793 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,794 : WARNING : duplicate word '347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,800 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,802 : WARNING : duplicate word '4679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,804 : WARNING : duplicate word '448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,806 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,807 : WARNING : duplicate word '668' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,808 : WARNING : duplicate word '647' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,809 : WARNING : duplicate word '73' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,810 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,812 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,843 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,844 : WARNING : duplicate word '14' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,845 : WARNING : duplicate word '874' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,851 : WARNING : duplicate word '1499' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,852 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,853 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,854 : WARNING : duplicate word '325' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,856 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,857 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,858 : WARNING : duplicate word '683' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,859 : WARNING : duplicate word '8332' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,861 : WARNING : duplicate word '623' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,863 : WARNING : duplicate word '247' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,864 : WARNING : duplicate word '341' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,865 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,865 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,866 : WARNING : duplicate word '395' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,867 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,868 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,869 : WARNING : duplicate word '047' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,871 : WARNING : duplicate word '969' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,873 : WARNING : duplicate word '175' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,874 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,877 : WARNING : duplicate word '4322' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,877 : WARNING : duplicate word '425' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,878 : WARNING : duplicate word '076' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,879 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,880 : WARNING : duplicate word '337' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,880 : WARNING : duplicate word '335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,881 : WARNING : duplicate word '209' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,882 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,882 : WARNING : duplicate word '145' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,883 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,884 : WARNING : duplicate word '031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,884 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,885 : WARNING : duplicate word '934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,885 : WARNING : duplicate word '791' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,886 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,887 : WARNING : duplicate word '14' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,891 : WARNING : duplicate word '5587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,892 : WARNING : duplicate word '393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,893 : WARNING : duplicate word '0033' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,894 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,896 : WARNING : duplicate word '044' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,898 : WARNING : duplicate word '3149' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,899 : WARNING : duplicate word '398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,901 : WARNING : duplicate word '694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,902 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,903 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,904 : WARNING : duplicate word '864' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,905 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,906 : WARNING : duplicate word '857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,907 : WARNING : duplicate word '2611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,908 : WARNING : duplicate word '463' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,909 : WARNING : duplicate word '1697' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,909 : WARNING : duplicate word '6783' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,910 : WARNING : duplicate word '276' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,912 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,913 : WARNING : duplicate word '143' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,913 : WARNING : duplicate word '673' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,914 : WARNING : duplicate word '396' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,915 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,917 : WARNING : duplicate word '69' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,919 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,920 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,921 : WARNING : duplicate word '321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,923 : WARNING : duplicate word '5526' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,925 : WARNING : duplicate word '901' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,925 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,926 : WARNING : duplicate word '346' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,927 : WARNING : duplicate word '8496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,927 : WARNING : duplicate word '836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,931 : WARNING : duplicate word '6083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,932 : WARNING : duplicate word '861' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,934 : WARNING : duplicate word '222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,935 : WARNING : duplicate word '643' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,936 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,937 : WARNING : duplicate word '3857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,938 : WARNING : duplicate word '7152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,940 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,941 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,942 : WARNING : duplicate word '9544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,943 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,944 : WARNING : duplicate word '4019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,945 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,946 : WARNING : duplicate word '158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,947 : WARNING : duplicate word '735' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,948 : WARNING : duplicate word '3073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,948 : WARNING : duplicate word '907' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,949 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,950 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,952 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,953 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,953 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,954 : WARNING : duplicate word '5863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,955 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,956 : WARNING : duplicate word '6296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,957 : WARNING : duplicate word '3819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,957 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,958 : WARNING : duplicate word '9077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,959 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,959 : WARNING : duplicate word '886' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,960 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,960 : WARNING : duplicate word '168' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:28,961 : WARNING : duplicate word '383' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,961 : WARNING : duplicate word '096' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,962 : WARNING : duplicate word '939' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,963 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,963 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,963 : WARNING : duplicate word '558' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,964 : WARNING : duplicate word '564' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,964 : WARNING : duplicate word '3923' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,965 : WARNING : duplicate word '172' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,965 : WARNING : duplicate word '5961' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,966 : WARNING : duplicate word '0767' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,966 : WARNING : duplicate word '07' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,967 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,967 : WARNING : duplicate word '818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,968 : WARNING : duplicate word '0468' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,968 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,969 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,969 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,970 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,970 : WARNING : duplicate word '6242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,971 : WARNING : duplicate word '986' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,972 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,973 : WARNING : duplicate word '275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,974 : WARNING : duplicate word '4544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,975 : WARNING : duplicate word '413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,975 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,984 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,985 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,986 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,987 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:28,997 : WARNING : duplicate word '287' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,000 : WARNING : duplicate word '824' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,001 : WARNING : duplicate word '938' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,002 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,003 : WARNING : duplicate word '168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,011 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,012 : WARNING : duplicate word '246' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,014 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,015 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,016 : WARNING : duplicate word '4608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,017 : WARNING : duplicate word '915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,021 : WARNING : duplicate word '93' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,022 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,026 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,027 : WARNING : duplicate word '707' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,030 : WARNING : duplicate word '166' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,032 : WARNING : duplicate word '851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,034 : WARNING : duplicate word '4324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,035 : WARNING : duplicate word '4072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,036 : WARNING : duplicate word '1423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,037 : WARNING : duplicate word '702' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,040 : WARNING : duplicate word '308' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,041 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,042 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,043 : WARNING : duplicate word '2708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,044 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,046 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,048 : WARNING : duplicate word '667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,050 : WARNING : duplicate word '727' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,051 : WARNING : duplicate word '013' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,052 : WARNING : duplicate word '768' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,053 : WARNING : duplicate word '913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,054 : WARNING : duplicate word '052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,055 : WARNING : duplicate word '751' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,056 : WARNING : duplicate word '763' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,062 : WARNING : duplicate word '717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,063 : WARNING : duplicate word '2601' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,064 : WARNING : duplicate word '984' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,065 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,066 : WARNING : duplicate word '464' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,067 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,068 : WARNING : duplicate word '072' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,069 : WARNING : duplicate word '256' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,070 : WARNING : duplicate word '035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,071 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,073 : WARNING : duplicate word '952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,074 : WARNING : duplicate word '538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,075 : WARNING : duplicate word '506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,076 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,077 : WARNING : duplicate word '3002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,078 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,079 : WARNING : duplicate word '7566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,081 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,083 : WARNING : duplicate word '388' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,084 : WARNING : duplicate word '7704' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,085 : WARNING : duplicate word '196' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,087 : WARNING : duplicate word '251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,088 : WARNING : duplicate word '793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,090 : WARNING : duplicate word '012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,091 : WARNING : duplicate word '578' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,092 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,092 : WARNING : duplicate word '364' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,093 : WARNING : duplicate word '716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,094 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,095 : WARNING : duplicate word '996' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,096 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,118 : WARNING : duplicate word '3005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,119 : WARNING : duplicate word '214' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,120 : WARNING : duplicate word '971' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,121 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,122 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,123 : WARNING : duplicate word '705' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,124 : WARNING : duplicate word '647' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,125 : WARNING : duplicate word '181' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,126 : WARNING : duplicate word '538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,127 : WARNING : duplicate word '4102' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,128 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,129 : WARNING : duplicate word '201' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,130 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,131 : WARNING : duplicate word '747' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,133 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,134 : WARNING : duplicate word '575' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,135 : WARNING : duplicate word '638' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,135 : WARNING : duplicate word '004' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,136 : WARNING : duplicate word '709' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,137 : WARNING : duplicate word '696' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,138 : WARNING : duplicate word '998' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,138 : WARNING : duplicate word '7566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,140 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,141 : WARNING : duplicate word '0134' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,142 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,142 : WARNING : duplicate word '403' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,143 : WARNING : duplicate word '8459' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,144 : WARNING : duplicate word '2869' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,145 : WARNING : duplicate word '1617' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,147 : WARNING : duplicate word '626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,148 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,150 : WARNING : duplicate word '673' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,151 : WARNING : duplicate word '3576' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,152 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,153 : WARNING : duplicate word '7094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,154 : WARNING : duplicate word '344' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,155 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,164 : WARNING : duplicate word '435' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,169 : WARNING : duplicate word '269' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,169 : WARNING : duplicate word '246' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,170 : WARNING : duplicate word '3639' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,171 : WARNING : duplicate word '665' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,172 : WARNING : duplicate word '439' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,173 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,174 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,175 : WARNING : duplicate word '149' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,176 : WARNING : duplicate word '2801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,177 : WARNING : duplicate word '5287' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,178 : WARNING : duplicate word '713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,179 : WARNING : duplicate word '6399' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,180 : WARNING : duplicate word '097' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,181 : WARNING : duplicate word '5305' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,182 : WARNING : duplicate word '1537' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,183 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,184 : WARNING : duplicate word '8037' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,185 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,187 : WARNING : duplicate word '3055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,188 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,190 : WARNING : duplicate word '194' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,191 : WARNING : duplicate word '417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,192 : WARNING : duplicate word '0966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,193 : WARNING : duplicate word '369' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,194 : WARNING : duplicate word '8692' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,197 : WARNING : duplicate word '5514' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,198 : WARNING : duplicate word '446' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,200 : WARNING : duplicate word '368' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,201 : WARNING : duplicate word '3084' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,202 : WARNING : duplicate word '2854' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,203 : WARNING : duplicate word '182' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,204 : WARNING : duplicate word '522' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,205 : WARNING : duplicate word '786' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,206 : WARNING : duplicate word '094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,207 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,208 : WARNING : duplicate word '988' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,208 : WARNING : duplicate word '367' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,209 : WARNING : duplicate word '457' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,210 : WARNING : duplicate word '296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,211 : WARNING : duplicate word '056' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,212 : WARNING : duplicate word '171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,213 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,214 : WARNING : duplicate word '233' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,214 : WARNING : duplicate word '807' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,216 : WARNING : duplicate word '484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,217 : WARNING : duplicate word '841' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,218 : WARNING : duplicate word '657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,220 : WARNING : duplicate word '442' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,220 : WARNING : duplicate word '174' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,221 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,224 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,225 : WARNING : duplicate word '692' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,226 : WARNING : duplicate word '3048' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,226 : WARNING : duplicate word '259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,227 : WARNING : duplicate word '031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,228 : WARNING : duplicate word '372' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,229 : WARNING : duplicate word '418' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,230 : WARNING : duplicate word '262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,231 : WARNING : duplicate word '005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,232 : WARNING : duplicate word '565' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,234 : WARNING : duplicate word '87' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,235 : WARNING : duplicate word '961' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,236 : WARNING : duplicate word '425' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,238 : WARNING : duplicate word '982' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,239 : WARNING : duplicate word '263' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,240 : WARNING : duplicate word '924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,241 : WARNING : duplicate word '332' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,242 : WARNING : duplicate word '944' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,243 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,244 : WARNING : duplicate word '082' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,246 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,247 : WARNING : duplicate word '239' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,247 : WARNING : duplicate word '9942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,249 : WARNING : duplicate word '886' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,250 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,253 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,254 : WARNING : duplicate word '949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,254 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,256 : WARNING : duplicate word '975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,257 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,258 : WARNING : duplicate word '201' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,259 : WARNING : duplicate word '5561' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,259 : WARNING : duplicate word '542' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,260 : WARNING : duplicate word '091' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,261 : WARNING : duplicate word '6311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,262 : WARNING : duplicate word '9828' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,263 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,264 : WARNING : duplicate word '5821' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,265 : WARNING : duplicate word '493' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,266 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,267 : WARNING : duplicate word '842' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,268 : WARNING : duplicate word '694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,269 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,269 : WARNING : duplicate word '1876' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,270 : WARNING : duplicate word '7046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,270 : WARNING : duplicate word '1769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,271 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,271 : WARNING : duplicate word '697' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,272 : WARNING : duplicate word '7762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,273 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,274 : WARNING : duplicate word '177' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,274 : WARNING : duplicate word '2819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,275 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,276 : WARNING : duplicate word '073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,276 : WARNING : duplicate word '682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,277 : WARNING : duplicate word '6921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,278 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,279 : WARNING : duplicate word '43' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,280 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,280 : WARNING : duplicate word '8952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,281 : WARNING : duplicate word '7163' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,281 : WARNING : duplicate word '0551' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,282 : WARNING : duplicate word '212' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,283 : WARNING : duplicate word '599' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,283 : WARNING : duplicate word '171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,284 : WARNING : duplicate word '076' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,285 : WARNING : duplicate word '3401' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,286 : WARNING : duplicate word '755' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,286 : WARNING : duplicate word '347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,287 : WARNING : duplicate word '0656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,287 : WARNING : duplicate word '083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,288 : WARNING : duplicate word '34' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,289 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,289 : WARNING : duplicate word '9529' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,290 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,290 : WARNING : duplicate word '931' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,291 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,291 : WARNING : duplicate word '829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,292 : WARNING : duplicate word '3534' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,292 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,293 : WARNING : duplicate word '1492' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,293 : WARNING : duplicate word '706' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,294 : WARNING : duplicate word '072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,294 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,295 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,296 : WARNING : duplicate word '6994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,297 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,297 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,298 : WARNING : duplicate word '7297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,299 : WARNING : duplicate word '3035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,300 : WARNING : duplicate word '8856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,301 : WARNING : duplicate word '559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,301 : WARNING : duplicate word '775' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,302 : WARNING : duplicate word '054' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,303 : WARNING : duplicate word '368' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,304 : WARNING : duplicate word '098' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,305 : WARNING : duplicate word '7766' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,307 : WARNING : duplicate word '5424' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,307 : WARNING : duplicate word '36' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,308 : WARNING : duplicate word '516' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,308 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,309 : WARNING : duplicate word '517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,309 : WARNING : duplicate word '354' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,310 : WARNING : duplicate word '705' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,310 : WARNING : duplicate word '317' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,311 : WARNING : duplicate word '842' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,311 : WARNING : duplicate word '912' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,312 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,313 : WARNING : duplicate word '0173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,315 : WARNING : duplicate word '258' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,318 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,319 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,347 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,348 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,349 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,351 : WARNING : duplicate word '07' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,352 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,352 : WARNING : duplicate word '049' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,353 : WARNING : duplicate word '471' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,354 : WARNING : duplicate word '25' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,354 : WARNING : duplicate word '7854' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,355 : WARNING : duplicate word '328' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,357 : WARNING : duplicate word '5344' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,358 : WARNING : duplicate word '691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,359 : WARNING : duplicate word '3296' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,359 : WARNING : duplicate word '4472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,360 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,361 : WARNING : duplicate word '696' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,364 : WARNING : duplicate word '278' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,365 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,366 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,368 : WARNING : duplicate word '6455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,369 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,370 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,371 : WARNING : duplicate word '2481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,373 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,375 : WARNING : duplicate word '2881' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,376 : WARNING : duplicate word '947' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,377 : WARNING : duplicate word '211' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,380 : WARNING : duplicate word '676' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,381 : WARNING : duplicate word '967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,381 : WARNING : duplicate word '177' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,382 : WARNING : duplicate word '567' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,383 : WARNING : duplicate word '1395' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,384 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,385 : WARNING : duplicate word '873' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,385 : WARNING : duplicate word '5407' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,386 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,387 : WARNING : duplicate word '194' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,388 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,389 : WARNING : duplicate word '1903' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,390 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,390 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,391 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,392 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,393 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,395 : WARNING : duplicate word '301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,397 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,399 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,399 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,400 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,401 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,401 : WARNING : duplicate word '543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,402 : WARNING : duplicate word '3235' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,403 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,408 : WARNING : duplicate word '396' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,409 : WARNING : duplicate word '402' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,410 : WARNING : duplicate word '092' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,413 : WARNING : duplicate word '732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,415 : WARNING : duplicate word '6893' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,416 : WARNING : duplicate word '6375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,418 : WARNING : duplicate word '988' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,419 : WARNING : duplicate word '944' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,420 : WARNING : duplicate word '063' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,421 : WARNING : duplicate word '712' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,422 : WARNING : duplicate word '645' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,423 : WARNING : duplicate word '795' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,424 : WARNING : duplicate word '399' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,425 : WARNING : duplicate word '532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,426 : WARNING : duplicate word '714' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,427 : WARNING : duplicate word '2335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,428 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,431 : WARNING : duplicate word '2245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,432 : WARNING : duplicate word '346' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,435 : WARNING : duplicate word '1029' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,436 : WARNING : duplicate word '9563' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,436 : WARNING : duplicate word '047' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,437 : WARNING : duplicate word '1719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,437 : WARNING : duplicate word '574' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,438 : WARNING : duplicate word '2077' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,438 : WARNING : duplicate word '2935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,441 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,441 : WARNING : duplicate word '246' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,442 : WARNING : duplicate word '6347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,443 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,444 : WARNING : duplicate word '15' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,444 : WARNING : duplicate word '0272' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,446 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,448 : WARNING : duplicate word '6532' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,450 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,451 : WARNING : duplicate word '65' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,452 : WARNING : duplicate word '208' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,452 : WARNING : duplicate word '3494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,453 : WARNING : duplicate word '832' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,454 : WARNING : duplicate word '656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,455 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,456 : WARNING : duplicate word '411' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,457 : WARNING : duplicate word '2521' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,458 : WARNING : duplicate word '4728' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,459 : WARNING : duplicate word '433' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,459 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,460 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,460 : WARNING : duplicate word '95525' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,461 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,463 : WARNING : duplicate word '756' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,464 : WARNING : duplicate word '3397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,465 : WARNING : duplicate word '299' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,466 : WARNING : duplicate word '118' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,466 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,467 : WARNING : duplicate word '199' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,468 : WARNING : duplicate word '718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,468 : WARNING : duplicate word '194' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,469 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,470 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,471 : WARNING : duplicate word '3805' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,472 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,473 : WARNING : duplicate word '987' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,473 : WARNING : duplicate word '2679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,474 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,474 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,475 : WARNING : duplicate word '517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,475 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,476 : WARNING : duplicate word '945' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,477 : WARNING : duplicate word '2787' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,479 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,479 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,480 : WARNING : duplicate word '7376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,480 : WARNING : duplicate word '385' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,481 : WARNING : duplicate word '879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,481 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,482 : WARNING : duplicate word '447' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,484 : WARNING : duplicate word '683' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,490 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,493 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,494 : WARNING : duplicate word '867' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,496 : WARNING : duplicate word '0137' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,497 : WARNING : duplicate word '476' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,498 : WARNING : duplicate word '665' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,499 : WARNING : duplicate word '8994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,500 : WARNING : duplicate word '118' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,501 : WARNING : duplicate word '731' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,501 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,502 : WARNING : duplicate word '2944' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,503 : WARNING : duplicate word '206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,504 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,506 : WARNING : duplicate word '536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,508 : WARNING : duplicate word '22' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,509 : WARNING : duplicate word '3543' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,510 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,514 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,515 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,517 : WARNING : duplicate word '395' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,518 : WARNING : duplicate word '652' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,519 : WARNING : duplicate word '957' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,521 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,522 : WARNING : duplicate word '934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,524 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,525 : WARNING : duplicate word '078' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,525 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,526 : WARNING : duplicate word '8848' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,528 : WARNING : duplicate word '392' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,529 : WARNING : duplicate word '233' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,530 : WARNING : duplicate word '8188' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,531 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,532 : WARNING : duplicate word '58' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,533 : WARNING : duplicate word '598' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,533 : WARNING : duplicate word '9345' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,535 : WARNING : duplicate word '3269' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,536 : WARNING : duplicate word '5484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,537 : WARNING : duplicate word '394' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,538 : WARNING : duplicate word '593' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,540 : WARNING : duplicate word '905' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,550 : WARNING : duplicate word '454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,551 : WARNING : duplicate word '1164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,552 : WARNING : duplicate word '396' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,553 : WARNING : duplicate word '865' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,553 : WARNING : duplicate word '43' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,554 : WARNING : duplicate word '156' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,555 : WARNING : duplicate word '069' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,558 : WARNING : duplicate word '822' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,559 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,560 : WARNING : duplicate word '2158' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,560 : WARNING : duplicate word '15' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,565 : WARNING : duplicate word '2201' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,566 : WARNING : duplicate word '294' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,568 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,569 : WARNING : duplicate word '611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,570 : WARNING : duplicate word '8047' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,571 : WARNING : duplicate word '511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,572 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,573 : WARNING : duplicate word '0548' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,574 : WARNING : duplicate word '3107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,575 : WARNING : duplicate word '587' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,577 : WARNING : duplicate word '6293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,579 : WARNING : duplicate word '7113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,580 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,581 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,582 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,583 : WARNING : duplicate word '652' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,585 : WARNING : duplicate word '123' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,595 : WARNING : duplicate word '73' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,596 : WARNING : duplicate word '016' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,616 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,616 : WARNING : duplicate word '717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,617 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,618 : WARNING : duplicate word '571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,618 : WARNING : duplicate word '242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,619 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,620 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,621 : WARNING : duplicate word '1535' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,622 : WARNING : duplicate word '563' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,623 : WARNING : duplicate word '264' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,624 : WARNING : duplicate word '931' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,624 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,625 : WARNING : duplicate word '7005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,625 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,626 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,635 : WARNING : duplicate word '758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,637 : WARNING : duplicate word '7129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,637 : WARNING : duplicate word '3356' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,638 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,639 : WARNING : duplicate word '8807' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,641 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,642 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,643 : WARNING : duplicate word '385' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,643 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,644 : WARNING : duplicate word '274' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,644 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,645 : WARNING : duplicate word '0923' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,646 : WARNING : duplicate word '506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,648 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,648 : WARNING : duplicate word '611' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,650 : WARNING : duplicate word '464' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,651 : WARNING : duplicate word '949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,651 : WARNING : duplicate word '07' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,652 : WARNING : duplicate word '4694' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,653 : WARNING : duplicate word '9321' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,653 : WARNING : duplicate word '0951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,654 : WARNING : duplicate word '887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,655 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,656 : WARNING : duplicate word '031' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,656 : WARNING : duplicate word '0044' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,657 : WARNING : duplicate word '4185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,658 : WARNING : duplicate word '2082' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,658 : WARNING : duplicate word '509' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,659 : WARNING : duplicate word '8729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,660 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,661 : WARNING : duplicate word '677' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,662 : WARNING : duplicate word '777' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,662 : WARNING : duplicate word '118' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,663 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,664 : WARNING : duplicate word '211' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,664 : WARNING : duplicate word '4734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,665 : WARNING : duplicate word '601' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,665 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,666 : WARNING : duplicate word '149' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,666 : WARNING : duplicate word '375' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,667 : WARNING : duplicate word '604' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,667 : WARNING : duplicate word '93' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,668 : WARNING : duplicate word '8765' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,668 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,669 : WARNING : duplicate word '092' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,669 : WARNING : duplicate word '519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,670 : WARNING : duplicate word '663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,670 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,671 : WARNING : duplicate word '225' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,671 : WARNING : duplicate word '417' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,672 : WARNING : duplicate word '353' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,673 : WARNING : duplicate word '437' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,673 : WARNING : duplicate word '476' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,674 : WARNING : duplicate word '975' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,674 : WARNING : duplicate word '237' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,675 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,676 : WARNING : duplicate word '4114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,676 : WARNING : duplicate word '712' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,677 : WARNING : duplicate word '0679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,679 : WARNING : duplicate word '3784' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,680 : WARNING : duplicate word '1536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,681 : WARNING : duplicate word '06' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,682 : WARNING : duplicate word '0909' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,683 : WARNING : duplicate word '169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,684 : WARNING : duplicate word '894' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,685 : WARNING : duplicate word '789' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,685 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,686 : WARNING : duplicate word '47' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,687 : WARNING : duplicate word '38' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,688 : WARNING : duplicate word '291' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,689 : WARNING : duplicate word '668' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,691 : WARNING : duplicate word '861' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,691 : WARNING : duplicate word '442' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,692 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,693 : WARNING : duplicate word '073' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,693 : WARNING : duplicate word '692' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,694 : WARNING : duplicate word '434' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,694 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,695 : WARNING : duplicate word '0716' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,698 : WARNING : duplicate word '3933' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,699 : WARNING : duplicate word '546' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,701 : WARNING : duplicate word '6104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,702 : WARNING : duplicate word '7186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,703 : WARNING : duplicate word '432' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,704 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,705 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,706 : WARNING : duplicate word '615' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,708 : WARNING : duplicate word '0582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,709 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,709 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,710 : WARNING : duplicate word '729' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,711 : WARNING : duplicate word '051' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,712 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,713 : WARNING : duplicate word '4399' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,714 : WARNING : duplicate word '956' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,715 : WARNING : duplicate word '663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,716 : WARNING : duplicate word '203' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,717 : WARNING : duplicate word '319' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,719 : WARNING : duplicate word '675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,720 : WARNING : duplicate word '059' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,720 : WARNING : duplicate word '171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,721 : WARNING : duplicate word '691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,722 : WARNING : duplicate word '058' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,724 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,725 : WARNING : duplicate word '389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,725 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,726 : WARNING : duplicate word '097' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,726 : WARNING : duplicate word '7109' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,727 : WARNING : duplicate word '879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,728 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,728 : WARNING : duplicate word '744' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,729 : WARNING : duplicate word '781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,732 : WARNING : duplicate word '736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,734 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,735 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,736 : WARNING : duplicate word '7479' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,737 : WARNING : duplicate word '52' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,738 : WARNING : duplicate word '237' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,739 : WARNING : duplicate word '085' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,740 : WARNING : duplicate word '494' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,741 : WARNING : duplicate word '736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,743 : WARNING : duplicate word '4383' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,744 : WARNING : duplicate word '956' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,745 : WARNING : duplicate word '304' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,746 : WARNING : duplicate word '951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,747 : WARNING : duplicate word '9563' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,748 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,749 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,750 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,750 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,751 : WARNING : duplicate word '6496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,752 : WARNING : duplicate word '8309' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,754 : WARNING : duplicate word '365' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,756 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,757 : WARNING : duplicate word '493' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,758 : WARNING : duplicate word '148' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,759 : WARNING : duplicate word '282' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,760 : WARNING : duplicate word '828' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,760 : WARNING : duplicate word '717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,761 : WARNING : duplicate word '923' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,762 : WARNING : duplicate word '461' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,762 : WARNING : duplicate word '353' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,763 : WARNING : duplicate word '113' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,763 : WARNING : duplicate word '6497' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,764 : WARNING : duplicate word '2183' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,764 : WARNING : duplicate word '943' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,765 : WARNING : duplicate word '857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,765 : WARNING : duplicate word '7966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,766 : WARNING : duplicate word '162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,766 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,767 : WARNING : duplicate word '693' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,768 : WARNING : duplicate word '5598' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,768 : WARNING : duplicate word '6313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,769 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,769 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,770 : WARNING : duplicate word '4799' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,770 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,771 : WARNING : duplicate word '1276' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,776 : WARNING : duplicate word '159' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,778 : WARNING : duplicate word '701' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,781 : WARNING : duplicate word '562' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,782 : WARNING : duplicate word '135' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,784 : WARNING : duplicate word '731' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,785 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,786 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,787 : WARNING : duplicate word '588' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,788 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,789 : WARNING : duplicate word '6353' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,790 : WARNING : duplicate word '449' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,791 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,792 : WARNING : duplicate word '424' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,793 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,794 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,795 : WARNING : duplicate word '133' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,796 : WARNING : duplicate word '364' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,797 : WARNING : duplicate word '4414' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,798 : WARNING : duplicate word '722' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,798 : WARNING : duplicate word '3698' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,799 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,800 : WARNING : duplicate word '2245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,801 : WARNING : duplicate word '5112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,802 : WARNING : duplicate word '3192' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,803 : WARNING : duplicate word '047' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,804 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,807 : WARNING : duplicate word '163' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,848 : WARNING : duplicate word '712' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,849 : WARNING : duplicate word '411' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,850 : WARNING : duplicate word '233' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,851 : WARNING : duplicate word '2453' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,852 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,852 : WARNING : duplicate word '46' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,853 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,854 : WARNING : duplicate word '036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,854 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,855 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,858 : WARNING : duplicate word '135' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,859 : WARNING : duplicate word '544' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,860 : WARNING : duplicate word '0546' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,863 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,864 : WARNING : duplicate word '471' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,866 : WARNING : duplicate word '18' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,868 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,869 : WARNING : duplicate word '913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,870 : WARNING : duplicate word '052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,871 : WARNING : duplicate word '026' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,872 : WARNING : duplicate word '687' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,874 : WARNING : duplicate word '012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,875 : WARNING : duplicate word '019' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,876 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,877 : WARNING : duplicate word '441' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,878 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,879 : WARNING : duplicate word '808' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,880 : WARNING : duplicate word '864' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,881 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,881 : WARNING : duplicate word '326' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,882 : WARNING : duplicate word '691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,883 : WARNING : duplicate word '7657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,884 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,886 : WARNING : duplicate word '4932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,886 : WARNING : duplicate word '8569' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,887 : WARNING : duplicate word '133' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,888 : WARNING : duplicate word '95' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,890 : WARNING : duplicate word '656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,891 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,891 : WARNING : duplicate word '85' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,892 : WARNING : duplicate word '005' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,893 : WARNING : duplicate word '389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,893 : WARNING : duplicate word '8332' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,894 : WARNING : duplicate word '1932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,895 : WARNING : duplicate word '5267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,896 : WARNING : duplicate word '482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,897 : WARNING : duplicate word '305' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,898 : WARNING : duplicate word '918' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,900 : WARNING : duplicate word '984' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,901 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,902 : WARNING : duplicate word '101' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,903 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,904 : WARNING : duplicate word '983' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,905 : WARNING : duplicate word '845' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,908 : WARNING : duplicate word '602' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,909 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,910 : WARNING : duplicate word '82' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,913 : WARNING : duplicate word '9372' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,914 : WARNING : duplicate word '106' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,916 : WARNING : duplicate word '21' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,918 : WARNING : duplicate word '5764' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,919 : WARNING : duplicate word '252' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,920 : WARNING : duplicate word '4737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,921 : WARNING : duplicate word '541' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,922 : WARNING : duplicate word '767' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,923 : WARNING : duplicate word '086' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,924 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,924 : WARNING : duplicate word '62' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,925 : WARNING : duplicate word '298' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,926 : WARNING : duplicate word '972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,927 : WARNING : duplicate word '9612' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,928 : WARNING : duplicate word '358' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,929 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,930 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,931 : WARNING : duplicate word '239' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,932 : WARNING : duplicate word '9052' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,933 : WARNING : duplicate word '324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,935 : WARNING : duplicate word '79' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,936 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,938 : WARNING : duplicate word '176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,939 : WARNING : duplicate word '2348' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,941 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,942 : WARNING : duplicate word '925' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,943 : WARNING : duplicate word '6622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,943 : WARNING : duplicate word '2366' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,944 : WARNING : duplicate word '087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,945 : WARNING : duplicate word '456' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,946 : WARNING : duplicate word '566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,947 : WARNING : duplicate word '4136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,948 : WARNING : duplicate word '076' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,949 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,950 : WARNING : duplicate word '5316' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,951 : WARNING : duplicate word '872' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,952 : WARNING : duplicate word '711' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,952 : WARNING : duplicate word '949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,953 : WARNING : duplicate word '394' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:29,953 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,954 : WARNING : duplicate word '3585' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,954 : WARNING : duplicate word '5216' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,955 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,956 : WARNING : duplicate word '411' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,957 : WARNING : duplicate word '571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,958 : WARNING : duplicate word '443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,958 : WARNING : duplicate word '401' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,959 : WARNING : duplicate word '114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,960 : WARNING : duplicate word '38' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,961 : WARNING : duplicate word '516' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,962 : WARNING : duplicate word '27' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,963 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,964 : WARNING : duplicate word '9854' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,965 : WARNING : duplicate word '148' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,966 : WARNING : duplicate word '416' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,967 : WARNING : duplicate word '373' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,968 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,969 : WARNING : duplicate word '8286' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,970 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,971 : WARNING : duplicate word '517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,972 : WARNING : duplicate word '915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,973 : WARNING : duplicate word '734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,974 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,975 : WARNING : duplicate word '951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,976 : WARNING : duplicate word '672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,977 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,978 : WARNING : duplicate word '644' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,979 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,980 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,981 : WARNING : duplicate word '281' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,982 : WARNING : duplicate word '364' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,983 : WARNING : duplicate word '883' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,984 : WARNING : duplicate word '2838' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,988 : WARNING : duplicate word '977' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,998 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:29,999 : WARNING : duplicate word '964' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,001 : WARNING : duplicate word '342' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,003 : WARNING : duplicate word '7367' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,004 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,005 : WARNING : duplicate word '661' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,006 : WARNING : duplicate word '2758' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,007 : WARNING : duplicate word '645' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,008 : WARNING : duplicate word '867' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,009 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,010 : WARNING : duplicate word '1307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,010 : WARNING : duplicate word '8' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,011 : WARNING : duplicate word '631' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,012 : WARNING : duplicate word '509' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,015 : WARNING : duplicate word '204' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,017 : WARNING : duplicate word '221' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,017 : WARNING : duplicate word '4672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,020 : WARNING : duplicate word '6266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,020 : WARNING : duplicate word '803' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,022 : WARNING : duplicate word '325' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,023 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,023 : WARNING : duplicate word '698' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,024 : WARNING : duplicate word '549' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,024 : WARNING : duplicate word '922' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,025 : WARNING : duplicate word '374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,025 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,026 : WARNING : duplicate word '4566' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,026 : WARNING : duplicate word '7965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,027 : WARNING : duplicate word '259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,029 : WARNING : duplicate word '8451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,030 : WARNING : duplicate word '95' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,031 : WARNING : duplicate word '658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,031 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,033 : WARNING : duplicate word '6804' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,036 : WARNING : duplicate word '226' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,037 : WARNING : duplicate word '426' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,037 : WARNING : duplicate word '425' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,038 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,039 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,041 : WARNING : duplicate word '73571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,042 : WARNING : duplicate word '927' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,043 : WARNING : duplicate word '2192' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,044 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,045 : WARNING : duplicate word '661' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,045 : WARNING : duplicate word '025' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,047 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,048 : WARNING : duplicate word '685' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,049 : WARNING : duplicate word '205' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,051 : WARNING : duplicate word '3812' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,052 : WARNING : duplicate word '913' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,053 : WARNING : duplicate word '722' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,053 : WARNING : duplicate word '1413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,054 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,054 : WARNING : duplicate word '801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,055 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,056 : WARNING : duplicate word '5268' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,057 : WARNING : duplicate word '599' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,058 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,059 : WARNING : duplicate word '962' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,060 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,060 : WARNING : duplicate word '3552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,061 : WARNING : duplicate word '26' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,062 : WARNING : duplicate word '624' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,063 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,064 : WARNING : duplicate word '827' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,065 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,066 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,066 : WARNING : duplicate word '438' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,067 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,102 : WARNING : duplicate word '659' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,103 : WARNING : duplicate word '803' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,103 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,104 : WARNING : duplicate word '165' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,104 : WARNING : duplicate word '822' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,105 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,106 : WARNING : duplicate word '4614' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,108 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,109 : WARNING : duplicate word '3926' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,110 : WARNING : duplicate word '397' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,110 : WARNING : duplicate word '81' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,111 : WARNING : duplicate word '6756' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,112 : WARNING : duplicate word '657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,113 : WARNING : duplicate word '155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,113 : WARNING : duplicate word '7229' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,115 : WARNING : duplicate word '972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,116 : WARNING : duplicate word '118' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,119 : WARNING : duplicate word '577' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,121 : WARNING : duplicate word '757' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,125 : WARNING : duplicate word '715' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,126 : WARNING : duplicate word '749' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,127 : WARNING : duplicate word '298' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,130 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,131 : WARNING : duplicate word '965' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,132 : WARNING : duplicate word '3222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,132 : WARNING : duplicate word '282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,133 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,133 : WARNING : duplicate word '982' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,134 : WARNING : duplicate word '658' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,135 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,136 : WARNING : duplicate word '96' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,137 : WARNING : duplicate word '7671' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,138 : WARNING : duplicate word '319' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,140 : WARNING : duplicate word '682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,141 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,142 : WARNING : duplicate word '7398' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,143 : WARNING : duplicate word '4979' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,147 : WARNING : duplicate word '973' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,149 : WARNING : duplicate word '5087' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,152 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,152 : WARNING : duplicate word '248' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,153 : WARNING : duplicate word '891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,153 : WARNING : duplicate word '168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,154 : WARNING : duplicate word '618' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,154 : WARNING : duplicate word '1284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,155 : WARNING : duplicate word '4164' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,156 : WARNING : duplicate word '615' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,158 : WARNING : duplicate word '206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,160 : WARNING : duplicate word '167' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,165 : WARNING : duplicate word '592' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,166 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,167 : WARNING : duplicate word '457' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,168 : WARNING : duplicate word '6' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,169 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,169 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,170 : WARNING : duplicate word '011' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,171 : WARNING : duplicate word '892' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,172 : WARNING : duplicate word '8564' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,175 : WARNING : duplicate word '2055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,176 : WARNING : duplicate word '5747' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,176 : WARNING : duplicate word '2857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,177 : WARNING : duplicate word '045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,178 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,179 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,180 : WARNING : duplicate word '236' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,182 : WARNING : duplicate word '466' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,182 : WARNING : duplicate word '4297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,183 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,184 : WARNING : duplicate word '7521' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,185 : WARNING : duplicate word '079' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,187 : WARNING : duplicate word '575' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,188 : WARNING : duplicate word '257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,188 : WARNING : duplicate word '405' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,190 : WARNING : duplicate word '4887' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,190 : WARNING : duplicate word '429' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,191 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,192 : WARNING : duplicate word '955' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,193 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,194 : WARNING : duplicate word '431' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,195 : WARNING : duplicate word '0103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,196 : WARNING : duplicate word '9169' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,197 : WARNING : duplicate word '949' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,197 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,198 : WARNING : duplicate word '999' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,199 : WARNING : duplicate word '924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,200 : WARNING : duplicate word '877' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,202 : WARNING : duplicate word '3089' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,202 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,203 : WARNING : duplicate word '749' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,203 : WARNING : duplicate word '667' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,204 : WARNING : duplicate word '043' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,204 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,205 : WARNING : duplicate word '642' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,205 : WARNING : duplicate word '402' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,206 : WARNING : duplicate word '744' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,208 : WARNING : duplicate word '733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,209 : WARNING : duplicate word '808' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,209 : WARNING : duplicate word '77' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,210 : WARNING : duplicate word '2823' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,211 : WARNING : duplicate word '608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,213 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,215 : WARNING : duplicate word '3963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,218 : WARNING : duplicate word '286' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,219 : WARNING : duplicate word '945' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,221 : WARNING : duplicate word '0496' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,222 : WARNING : duplicate word '508' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,224 : WARNING : duplicate word '821' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,225 : WARNING : duplicate word '6301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,226 : WARNING : duplicate word '3084' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,229 : WARNING : duplicate word '072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,232 : WARNING : duplicate word '048' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,233 : WARNING : duplicate word '2944' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,234 : WARNING : duplicate word '2413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,235 : WARNING : duplicate word '391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,236 : WARNING : duplicate word '7524' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,237 : WARNING : duplicate word '429' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,238 : WARNING : duplicate word '9145' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,239 : WARNING : duplicate word '885' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,240 : WARNING : duplicate word '874' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,241 : WARNING : duplicate word '339' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,242 : WARNING : duplicate word '3663' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,244 : WARNING : duplicate word '932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,246 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,247 : WARNING : duplicate word '444' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,247 : WARNING : duplicate word '2349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,248 : WARNING : duplicate word '301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,248 : WARNING : duplicate word '839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,249 : WARNING : duplicate word '433' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,250 : WARNING : duplicate word '637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,251 : WARNING : duplicate word '183' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,251 : WARNING : duplicate word '4359' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,252 : WARNING : duplicate word '2932' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,253 : WARNING : duplicate word '5219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,253 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,254 : WARNING : duplicate word '5376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,254 : WARNING : duplicate word '0235' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,255 : WARNING : duplicate word '152' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,255 : WARNING : duplicate word '443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,256 : WARNING : duplicate word '924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,257 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,259 : WARNING : duplicate word '84' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,260 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,263 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,265 : WARNING : duplicate word '836' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,266 : WARNING : duplicate word '4245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,266 : WARNING : duplicate word '5455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,267 : WARNING : duplicate word '454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,267 : WARNING : duplicate word '9155' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,268 : WARNING : duplicate word '126' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,268 : WARNING : duplicate word '401' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,268 : WARNING : duplicate word '1112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,269 : WARNING : duplicate word '243' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,269 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,270 : WARNING : duplicate word '7545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,271 : WARNING : duplicate word '102' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,272 : WARNING : duplicate word '2703' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,274 : WARNING : duplicate word '908' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,275 : WARNING : duplicate word '2951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,276 : WARNING : duplicate word '199' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,276 : WARNING : duplicate word '3288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,277 : WARNING : duplicate word '5182' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,278 : WARNING : duplicate word '925' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,280 : WARNING : duplicate word '847' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,281 : WARNING : duplicate word '002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,282 : WARNING : duplicate word '484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,283 : WARNING : duplicate word '776' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,284 : WARNING : duplicate word '266' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,285 : WARNING : duplicate word '363' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,286 : WARNING : duplicate word '837' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,286 : WARNING : duplicate word '088' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,287 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,287 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,288 : WARNING : duplicate word '84' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,289 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,289 : WARNING : duplicate word '9768' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,290 : WARNING : duplicate word '678' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,291 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,291 : WARNING : duplicate word '6666' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,292 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,294 : WARNING : duplicate word '891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,295 : WARNING : duplicate word '9719' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,297 : WARNING : duplicate word '578' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,298 : WARNING : duplicate word '014' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,299 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,299 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,300 : WARNING : duplicate word '085' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,301 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,301 : WARNING : duplicate word '7766' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,302 : WARNING : duplicate word '2489' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,302 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,303 : WARNING : duplicate word '572' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,304 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,304 : WARNING : duplicate word '1685' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,305 : WARNING : duplicate word '896' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,307 : WARNING : duplicate word '621' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,308 : WARNING : duplicate word '504' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,309 : WARNING : duplicate word '39' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,310 : WARNING : duplicate word '858' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,311 : WARNING : duplicate word '303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,313 : WARNING : duplicate word '388' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,341 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,341 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,342 : WARNING : duplicate word '3734' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,342 : WARNING : duplicate word '063' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,343 : WARNING : duplicate word '704' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,344 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,344 : WARNING : duplicate word '816' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,345 : WARNING : duplicate word '819' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,346 : WARNING : duplicate word '3762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,348 : WARNING : duplicate word '0443' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,348 : WARNING : duplicate word '0583' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,349 : WARNING : duplicate word '811' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,350 : WARNING : duplicate word '403' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,351 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,352 : WARNING : duplicate word '335' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,352 : WARNING : duplicate word '2132' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,353 : WARNING : duplicate word '665' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,354 : WARNING : duplicate word '187' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,355 : WARNING : duplicate word '652' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,361 : WARNING : duplicate word '32' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,362 : WARNING : duplicate word '5423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,363 : WARNING : duplicate word '2175' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,364 : WARNING : duplicate word '995' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,366 : WARNING : duplicate word '176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,367 : WARNING : duplicate word '452' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,368 : WARNING : duplicate word '2347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,368 : WARNING : duplicate word '882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,369 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,370 : WARNING : duplicate word '8536' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,371 : WARNING : duplicate word '835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,371 : WARNING : duplicate word '92' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,372 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,373 : WARNING : duplicate word '572' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,374 : WARNING : duplicate word '8125' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,375 : WARNING : duplicate word '094' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,376 : WARNING : duplicate word '849' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,377 : WARNING : duplicate word '5849' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,379 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,380 : WARNING : duplicate word '9672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,381 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,382 : WARNING : duplicate word '349' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,383 : WARNING : duplicate word '666' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,383 : WARNING : duplicate word '104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,384 : WARNING : duplicate word '709' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,384 : WARNING : duplicate word '972' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,385 : WARNING : duplicate word '957' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,385 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,386 : WARNING : duplicate word '612' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,386 : WARNING : duplicate word '103' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,387 : WARNING : duplicate word '418' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,387 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,388 : WARNING : duplicate word '278' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,388 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,390 : WARNING : duplicate word '994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,391 : WARNING : duplicate word '422' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,392 : WARNING : duplicate word '852' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,392 : WARNING : duplicate word '114' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,393 : WARNING : duplicate word '934' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,393 : WARNING : duplicate word '1664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,397 : WARNING : duplicate word '213' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,398 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,399 : WARNING : duplicate word '255' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,401 : WARNING : duplicate word '875' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,402 : WARNING : duplicate word '921' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,402 : WARNING : duplicate word '915' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,403 : WARNING : duplicate word '7316' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,403 : WARNING : duplicate word '185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,404 : WARNING : duplicate word '17' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,405 : WARNING : duplicate word '302' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,405 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,406 : WARNING : duplicate word '006' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,407 : WARNING : duplicate word '313' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,407 : WARNING : duplicate word '7793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,408 : WARNING : duplicate word '8199' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,409 : WARNING : duplicate word '2437' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,409 : WARNING : duplicate word '7095' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,410 : WARNING : duplicate word '6008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,411 : WARNING : duplicate word '427' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,412 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,413 : WARNING : duplicate word '538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,413 : WARNING : duplicate word '334' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,414 : WARNING : duplicate word '259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,414 : WARNING : duplicate word '42' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,415 : WARNING : duplicate word '542' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,416 : WARNING : duplicate word '11' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,416 : WARNING : duplicate word '4635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,417 : WARNING : duplicate word '2233' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,417 : WARNING : duplicate word '454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,418 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,418 : WARNING : duplicate word '413' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,419 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,419 : WARNING : duplicate word '8591' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,420 : WARNING : duplicate word '505' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,420 : WARNING : duplicate word '589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,421 : WARNING : duplicate word '941' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,421 : WARNING : duplicate word '144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,422 : WARNING : duplicate word '4136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,423 : WARNING : duplicate word '34' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,423 : WARNING : duplicate word '0487' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,424 : WARNING : duplicate word '378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,424 : WARNING : duplicate word '0853' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,425 : WARNING : duplicate word '0765' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,425 : WARNING : duplicate word '489' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,426 : WARNING : duplicate word '142' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,426 : WARNING : duplicate word '58' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,427 : WARNING : duplicate word '732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,427 : WARNING : duplicate word '361' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,428 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,429 : WARNING : duplicate word '018' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,430 : WARNING : duplicate word '673' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,431 : WARNING : duplicate word '481' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,432 : WARNING : duplicate word '935' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,433 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,434 : WARNING : duplicate word '8409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,440 : WARNING : duplicate word '6626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,441 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,443 : WARNING : duplicate word '937' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,443 : WARNING : duplicate word '5961' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,444 : WARNING : duplicate word '04' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,447 : WARNING : duplicate word '851' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,448 : WARNING : duplicate word '5331' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,449 : WARNING : duplicate word '132' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,451 : WARNING : duplicate word '613' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,452 : WARNING : duplicate word '202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,452 : WARNING : duplicate word '262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,453 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,453 : WARNING : duplicate word '941' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,454 : WARNING : duplicate word '151' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,454 : WARNING : duplicate word '6242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,455 : WARNING : duplicate word '813' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,456 : WARNING : duplicate word '9116' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,457 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,459 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,460 : WARNING : duplicate word '739' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,462 : WARNING : duplicate word '0839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,463 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,463 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,464 : WARNING : duplicate word '609' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,465 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,466 : WARNING : duplicate word '827' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,466 : WARNING : duplicate word '338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,467 : WARNING : duplicate word '48' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,468 : WARNING : duplicate word '3121' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,468 : WARNING : duplicate word '439' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,469 : WARNING : duplicate word '7318' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,469 : WARNING : duplicate word '392' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,470 : WARNING : duplicate word '619' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,471 : WARNING : duplicate word '961' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,471 : WARNING : duplicate word '738' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,472 : WARNING : duplicate word '385' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,475 : WARNING : duplicate word '3718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,476 : WARNING : duplicate word '1681' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,476 : WARNING : duplicate word '528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,477 : WARNING : duplicate word '886' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,478 : WARNING : duplicate word '285' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,482 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,483 : WARNING : duplicate word '03' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,486 : WARNING : duplicate word '643' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,488 : WARNING : duplicate word '262' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,490 : WARNING : duplicate word '004' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,491 : WARNING : duplicate word '024' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,493 : WARNING : duplicate word '59' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,496 : WARNING : duplicate word '994' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,497 : WARNING : duplicate word '67' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,498 : WARNING : duplicate word '347' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,500 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,502 : WARNING : duplicate word '188' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,509 : WARNING : duplicate word '797' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,510 : WARNING : duplicate word '558' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,512 : WARNING : duplicate word '083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,512 : WARNING : duplicate word '389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,513 : WARNING : duplicate word '951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,514 : WARNING : duplicate word '27' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,514 : WARNING : duplicate word '1589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,516 : WARNING : duplicate word '215' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,517 : WARNING : duplicate word '9202' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,517 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,518 : WARNING : duplicate word '3928' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,518 : WARNING : duplicate word '888' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,519 : WARNING : duplicate word '506' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,520 : WARNING : duplicate word '9141' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,525 : WARNING : duplicate word '6791' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,526 : WARNING : duplicate word '1011' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,527 : WARNING : duplicate word '3591' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,528 : WARNING : duplicate word '183' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,533 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,534 : WARNING : duplicate word '144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,536 : WARNING : duplicate word '95' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,539 : WARNING : duplicate word '963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,540 : WARNING : duplicate word '9882' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,541 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,542 : WARNING : duplicate word '327' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,543 : WARNING : duplicate word '4394' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,545 : WARNING : duplicate word '0365' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,546 : WARNING : duplicate word '54' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,547 : WARNING : duplicate word '403' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,548 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,550 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,551 : WARNING : duplicate word '3515' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,553 : WARNING : duplicate word '436' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,591 : WARNING : duplicate word '815' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,593 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,598 : WARNING : duplicate word '0649' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,599 : WARNING : duplicate word '9953' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,600 : WARNING : duplicate word '1707' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,602 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,603 : WARNING : duplicate word '578' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,604 : WARNING : duplicate word '244' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,605 : WARNING : duplicate word '708' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,606 : WARNING : duplicate word '538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,609 : WARNING : duplicate word '573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,610 : WARNING : duplicate word '895' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,612 : WARNING : duplicate word '1098' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,615 : WARNING : duplicate word '115' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,618 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,620 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,621 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,624 : WARNING : duplicate word '0651' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,625 : WARNING : duplicate word '1068' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,625 : WARNING : duplicate word '28' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,626 : WARNING : duplicate word '68' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,626 : WARNING : duplicate word '4807' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,627 : WARNING : duplicate word '7' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,627 : WARNING : duplicate word '0967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,629 : WARNING : duplicate word '465' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,631 : WARNING : duplicate word '033' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,632 : WARNING : duplicate word '759' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,633 : WARNING : duplicate word '37' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,634 : WARNING : duplicate word '725' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,636 : WARNING : duplicate word '301' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,638 : WARNING : duplicate word '3839' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,639 : WARNING : duplicate word '3558' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,642 : WARNING : duplicate word '564' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,643 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,644 : WARNING : duplicate word '012' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,645 : WARNING : duplicate word '2682' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,647 : WARNING : duplicate word '6482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,649 : WARNING : duplicate word '063' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,651 : WARNING : duplicate word '654' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,652 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,653 : WARNING : duplicate word '2909' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,654 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,655 : WARNING : duplicate word '3454' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,655 : WARNING : duplicate word '664' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,656 : WARNING : duplicate word '53' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,657 : WARNING : duplicate word '6637' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,658 : WARNING : duplicate word '284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,660 : WARNING : duplicate word '871' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,660 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,661 : WARNING : duplicate word '3709' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,662 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,663 : WARNING : duplicate word '594' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,663 : WARNING : duplicate word '848' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,664 : WARNING : duplicate word '998' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,665 : WARNING : duplicate word '743' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,666 : WARNING : duplicate word '176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,667 : WARNING : duplicate word '358' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,667 : WARNING : duplicate word '021' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,668 : WARNING : duplicate word '853' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,669 : WARNING : duplicate word '111' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,669 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,670 : WARNING : duplicate word '4228' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,670 : WARNING : duplicate word '45' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,671 : WARNING : duplicate word '779' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,674 : WARNING : duplicate word '02' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,674 : WARNING : duplicate word '256' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,675 : WARNING : duplicate word '606' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,679 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,681 : WARNING : duplicate word '041' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,681 : WARNING : duplicate word '641' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,682 : WARNING : duplicate word '551' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,683 : WARNING : duplicate word '12' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,683 : WARNING : duplicate word '462' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,683 : WARNING : duplicate word '307' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,684 : WARNING : duplicate word '502' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,684 : WARNING : duplicate word '873' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,685 : WARNING : duplicate word '547' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,686 : WARNING : duplicate word '8974' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,687 : WARNING : duplicate word '088' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,688 : WARNING : duplicate word '891' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,690 : WARNING : duplicate word '093' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,691 : WARNING : duplicate word '554' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,692 : WARNING : duplicate word '191' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,693 : WARNING : duplicate word '7389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,693 : WARNING : duplicate word '885' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,697 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,698 : WARNING : duplicate word '1448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,699 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,702 : WARNING : duplicate word '546' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,703 : WARNING : duplicate word '741' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,704 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,704 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,705 : WARNING : duplicate word '2926' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,705 : WARNING : duplicate word '323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,706 : WARNING : duplicate word '2573' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,707 : WARNING : duplicate word '8161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,708 : WARNING : duplicate word '8144' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,709 : WARNING : duplicate word '657' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,710 : WARNING : duplicate word '171' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,710 : WARNING : duplicate word '434' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,711 : WARNING : duplicate word '7357' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,712 : WARNING : duplicate word '771' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,712 : WARNING : duplicate word '8608' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,713 : WARNING : duplicate word '88' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,714 : WARNING : duplicate word '752' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,714 : WARNING : duplicate word '355' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,715 : WARNING : duplicate word '815' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,718 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,718 : WARNING : duplicate word '964' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,722 : WARNING : duplicate word '288' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,724 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,725 : WARNING : duplicate word '513' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,726 : WARNING : duplicate word '153' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,727 : WARNING : duplicate word '991' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,728 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,730 : WARNING : duplicate word '817' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,731 : WARNING : duplicate word '9744' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,732 : WARNING : duplicate word '9703' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,733 : WARNING : duplicate word '8223' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,733 : WARNING : duplicate word '5916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,734 : WARNING : duplicate word '4409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,735 : WARNING : duplicate word '5998' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,735 : WARNING : duplicate word '718' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,736 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,738 : WARNING : duplicate word '959' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,739 : WARNING : duplicate word '2559' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,741 : WARNING : duplicate word '038' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,742 : WARNING : duplicate word '034' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,742 : WARNING : duplicate word '63' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,743 : WARNING : duplicate word '1451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,747 : WARNING : duplicate word '748' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,748 : WARNING : duplicate word '0853' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,750 : WARNING : duplicate word '745' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,751 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,753 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,754 : WARNING : duplicate word '951' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,754 : WARNING : duplicate word '6429' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,755 : WARNING : duplicate word '455' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,755 : WARNING : duplicate word '511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,756 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,757 : WARNING : duplicate word '017' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,758 : WARNING : duplicate word '041' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,761 : WARNING : duplicate word '388' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,767 : WARNING : duplicate word '675' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,768 : WARNING : duplicate word '1139' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,768 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,769 : WARNING : duplicate word '1126' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,769 : WARNING : duplicate word '5003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,770 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,770 : WARNING : duplicate word '1773' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,771 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,772 : WARNING : duplicate word '35526' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,775 : WARNING : duplicate word '775' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,776 : WARNING : duplicate word '371' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,777 : WARNING : duplicate word '9177' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,777 : WARNING : duplicate word '5219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,779 : WARNING : duplicate word '97' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,782 : WARNING : duplicate word '159' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,783 : WARNING : duplicate word '384' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,785 : WARNING : duplicate word '486' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,785 : WARNING : duplicate word '4728' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,786 : WARNING : duplicate word '6674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,787 : WARNING : duplicate word '618' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,788 : WARNING : duplicate word '953' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,789 : WARNING : duplicate word '6869' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,790 : WARNING : duplicate word '5654' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,791 : WARNING : duplicate word '6105' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,792 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,793 : WARNING : duplicate word '377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,796 : WARNING : duplicate word '5986' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,800 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,801 : WARNING : duplicate word '9919' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,802 : WARNING : duplicate word '382' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,803 : WARNING : duplicate word '75' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,804 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,804 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,805 : WARNING : duplicate word '3251' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,806 : WARNING : duplicate word '145' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,809 : WARNING : duplicate word '995' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,811 : WARNING : duplicate word '039' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,812 : WARNING : duplicate word '5691' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,813 : WARNING : duplicate word '348' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,814 : WARNING : duplicate word '418' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,819 : WARNING : duplicate word '2457' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,819 : WARNING : duplicate word '49' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,820 : WARNING : duplicate word '474' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,821 : WARNING : duplicate word '045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,822 : WARNING : duplicate word '357' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,824 : WARNING : duplicate word '625' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,825 : WARNING : duplicate word '7004' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,825 : WARNING : duplicate word '061' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,826 : WARNING : duplicate word '3879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,827 : WARNING : duplicate word '8222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,827 : WARNING : duplicate word '374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,828 : WARNING : duplicate word '604' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,829 : WARNING : duplicate word '341' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,831 : WARNING : duplicate word '855' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,832 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,832 : WARNING : duplicate word '635' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,833 : WARNING : duplicate word '599' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,861 : WARNING : duplicate word '597' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,862 : WARNING : duplicate word '5377' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,862 : WARNING : duplicate word '502' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,863 : WARNING : duplicate word '943' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,864 : WARNING : duplicate word '245' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,866 : WARNING : duplicate word '008' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,868 : WARNING : duplicate word '6326' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,869 : WARNING : duplicate word '527' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,869 : WARNING : duplicate word '028' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,870 : WARNING : duplicate word '0656' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,870 : WARNING : duplicate word '974' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,871 : WARNING : duplicate word '6449' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,872 : WARNING : duplicate word '259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,873 : WARNING : duplicate word '726' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,875 : WARNING : duplicate word '843' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,875 : WARNING : duplicate word '4528' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,876 : WARNING : duplicate word '865' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,877 : WARNING : duplicate word '394' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,877 : WARNING : duplicate word '8404' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,878 : WARNING : duplicate word '9357' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,880 : WARNING : duplicate word '812' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,881 : WARNING : duplicate word '672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,882 : WARNING : duplicate word '227' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,882 : WARNING : duplicate word '189' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,883 : WARNING : duplicate word '0863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,883 : WARNING : duplicate word '9282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,884 : WARNING : duplicate word '98' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,884 : WARNING : duplicate word '163' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,885 : WARNING : duplicate word '3015' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,885 : WARNING : duplicate word '695' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,886 : WARNING : duplicate word '4863' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,887 : WARNING : duplicate word '645' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,888 : WARNING : duplicate word '946' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,889 : WARNING : duplicate word '6639' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,891 : WARNING : duplicate word '622' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,891 : WARNING : duplicate word '1643' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,892 : WARNING : duplicate word '868' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,893 : WARNING : duplicate word '589' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,894 : WARNING : duplicate word '046' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,896 : WARNING : duplicate word '203' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,898 : WARNING : duplicate word '514' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,899 : WARNING : duplicate word '324' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,899 : WARNING : duplicate word '3168' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,900 : WARNING : duplicate word '2' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,901 : WARNING : duplicate word '261' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,903 : WARNING : duplicate word '104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,904 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,905 : WARNING : duplicate word '9393' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,905 : WARNING : duplicate word '376' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,907 : WARNING : duplicate word '33' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,909 : WARNING : duplicate word '558' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,910 : WARNING : duplicate word '104' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,911 : WARNING : duplicate word '4733' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,912 : WARNING : duplicate word '1293' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,913 : WARNING : duplicate word '514' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,916 : WARNING : duplicate word '1574' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,918 : WARNING : duplicate word '3003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,919 : WARNING : duplicate word '14' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,919 : WARNING : duplicate word '4035' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,920 : WARNING : duplicate word '124' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,920 : WARNING : duplicate word '992' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,922 : WARNING : duplicate word '68' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,922 : WARNING : duplicate word '7101' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,924 : WARNING : duplicate word '173' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,924 : WARNING : duplicate word '267' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,925 : WARNING : duplicate word '99' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,926 : WARNING : duplicate word '76' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,926 : WARNING : duplicate word '033' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,927 : WARNING : duplicate word '203' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,927 : WARNING : duplicate word '6482' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,928 : WARNING : duplicate word '2752' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,929 : WARNING : duplicate word '828' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,930 : WARNING : duplicate word '3002' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,930 : WARNING : duplicate word '275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,931 : WARNING : duplicate word '552' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,932 : WARNING : duplicate word '523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,932 : WARNING : duplicate word '13' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,933 : WARNING : duplicate word '234' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,933 : WARNING : duplicate word '099' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,934 : WARNING : duplicate word '09' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,934 : WARNING : duplicate word '769' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,935 : WARNING : duplicate word '231' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,935 : WARNING : duplicate word '98' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,936 : WARNING : duplicate word '2493' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,937 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,938 : WARNING : duplicate word '468' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,938 : WARNING : duplicate word '3499' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:30,939 : WARNING : duplicate word '2818' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,940 : WARNING : duplicate word '945' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,940 : WARNING : duplicate word '805' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,944 : WARNING : duplicate word '2538' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,946 : WARNING : duplicate word '373' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,947 : WARNING : duplicate word '107' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,947 : WARNING : duplicate word '0549' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,948 : WARNING : duplicate word '747' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,948 : WARNING : duplicate word '282' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,949 : WARNING : duplicate word '732' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,950 : WARNING : duplicate word '3213' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,950 : WARNING : duplicate word '945' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,950 : WARNING : duplicate word '83' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,951 : WARNING : duplicate word '803' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,952 : WARNING : duplicate word '269' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,952 : WARNING : duplicate word '51' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,953 : WARNING : duplicate word '646' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,953 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,954 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,955 : WARNING : duplicate word '491' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,955 : WARNING : duplicate word '057' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,958 : WARNING : duplicate word '295' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,958 : WARNING : duplicate word '971' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,959 : WARNING : duplicate word '1523' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,960 : WARNING : duplicate word '081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,960 : WARNING : duplicate word '3963' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,961 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,963 : WARNING : duplicate word '9374' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,964 : WARNING : duplicate word '4' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,965 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,966 : WARNING : duplicate word '8781' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,967 : WARNING : duplicate word '713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,968 : WARNING : duplicate word '0864' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,969 : WARNING : duplicate word '599' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,969 : WARNING : duplicate word '043' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,970 : WARNING : duplicate word '015' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,970 : WARNING : duplicate word '072' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,971 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,971 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,972 : WARNING : duplicate word '249' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,972 : WARNING : duplicate word '713' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,973 : WARNING : duplicate word '4579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,974 : WARNING : duplicate word '74' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,975 : WARNING : duplicate word '978' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,975 : WARNING : duplicate word '219' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,976 : WARNING : duplicate word '859' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,977 : WARNING : duplicate word '24' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,980 : WARNING : duplicate word '1081' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,981 : WARNING : duplicate word '702' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,981 : WARNING : duplicate word '479' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,982 : WARNING : duplicate word '477' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,982 : WARNING : duplicate word '263' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,983 : WARNING : duplicate word '3' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,983 : WARNING : duplicate word '0273' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,984 : WARNING : duplicate word '292' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,984 : WARNING : duplicate word '686' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,985 : WARNING : duplicate word '117' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,985 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,986 : WARNING : duplicate word '741' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,986 : WARNING : duplicate word '194' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,987 : WARNING : duplicate word '911' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,987 : WARNING : duplicate word '1323' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:30,988 : WARNING : duplicate word '484' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,001 : WARNING : duplicate word '189' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,007 : WARNING : duplicate word '29' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,007 : WARNING : duplicate word '056' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,011 : WARNING : duplicate word '699' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,011 : WARNING : duplicate word '737' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,012 : WARNING : duplicate word '655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,013 : WARNING : duplicate word '857' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,014 : WARNING : duplicate word '672' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,015 : WARNING : duplicate word '333' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:31,015 : WARNING : duplicate word '8391' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,020 : WARNING : duplicate word '5453' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,024 : WARNING : duplicate word '448' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,025 : WARNING : duplicate word '985' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,026 : WARNING : duplicate word '94' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,028 : WARNING : duplicate word '683' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,029 : WARNING : duplicate word '697' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,030 : WARNING : duplicate word '423' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,031 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,033 : WARNING : duplicate word '626' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,035 : WARNING : duplicate word '856' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,038 : WARNING : duplicate word '0517' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,039 : WARNING : duplicate word '2519' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,040 : WARNING : duplicate word '297' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,041 : WARNING : duplicate word '71' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,042 : WARNING : duplicate word '275' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,042 : WARNING : duplicate word '66' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,043 : WARNING : duplicate word '967' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,045 : WARNING : duplicate word '311' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,048 : WARNING : duplicate word '7472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,050 : WARNING : duplicate word '6036' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,057 : WARNING : duplicate word '8183' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,059 : WARNING : duplicate word '085' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,060 : WARNING : duplicate word '571' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,060 : WARNING : duplicate word '901' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,061 : WARNING : duplicate word '428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,062 : WARNING : duplicate word '421' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,063 : WARNING : duplicate word '627' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,064 : WARNING : duplicate word '4879' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,067 : WARNING : duplicate word '265' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,068 : WARNING : duplicate word '0055' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,070 : WARNING : duplicate word '5176' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,071 : WARNING : duplicate word '628' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,071 : WARNING : duplicate word '784' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,072 : WARNING : duplicate word '4669' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,074 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,075 : WARNING : duplicate word '57' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,076 : WARNING : duplicate word '1751' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,077 : WARNING : duplicate word '603' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,078 : WARNING : duplicate word '53' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,079 : WARNING : duplicate word '1' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,099 : WARNING : duplicate word '242' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,100 : WARNING : duplicate word '41' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,101 : WARNING : duplicate word '724' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,102 : WARNING : duplicate word '582' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,102 : WARNING : duplicate word '91' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,103 : WARNING : duplicate word '435' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,104 : WARNING : duplicate word '186' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,104 : WARNING : duplicate word '134' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,105 : WARNING : duplicate word '806' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,106 : WARNING : duplicate word '8257' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,106 : WARNING : duplicate word '2511' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,107 : WARNING : duplicate word '636' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,108 : WARNING : duplicate word '761' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,109 : WARNING : duplicate word '989' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,110 : WARNING : duplicate word '01' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,113 : WARNING : duplicate word '295' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,115 : WARNING : duplicate word '209' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,116 : WARNING : duplicate word '136' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,119 : WARNING : duplicate word '1198' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,120 : WARNING : duplicate word '1835' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,121 : WARNING : duplicate word '583' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,122 : WARNING : duplicate word '4042' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,124 : WARNING : duplicate word '9' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,125 : WARNING : duplicate word '389' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,126 : WARNING : duplicate word '312' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,127 : WARNING : duplicate word '648' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,128 : WARNING : duplicate word '64' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,129 : WARNING : duplicate word '395' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,130 : WARNING : duplicate word '2378' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,133 : WARNING : duplicate word '067' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,134 : WARNING : duplicate word '5' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:31,135 : WARNING : duplicate word '4162' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,138 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,140 : WARNING : duplicate word '161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,141 : WARNING : duplicate word '0206' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,142 : WARNING : duplicate word '112' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,143 : WARNING : duplicate word '1873' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,144 : WARNING : duplicate word '232' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,145 : WARNING : duplicate word '7916' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,149 : WARNING : duplicate word '4793' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,150 : WARNING : duplicate word '2653' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,153 : WARNING : duplicate word '231' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,153 : WARNING : duplicate word '8' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,154 : WARNING : duplicate word '44' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,155 : WARNING : duplicate word '7421' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,156 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,157 : WARNING : duplicate word '86' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,158 : WARNING : duplicate word '674' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,159 : WARNING : duplicate word '6503' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,160 : WARNING : duplicate word '78' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,161 : WARNING : duplicate word '346' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,162 : WARNING : duplicate word '445' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,162 : WARNING : duplicate word '129' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,163 : WARNING : duplicate word '962' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,163 : WARNING : duplicate word '4541' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,164 : WARNING : duplicate word '131' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,164 : WARNING : duplicate word '553' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,165 : WARNING : duplicate word '352' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,166 : WARNING : duplicate word '329' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,167 : WARNING : duplicate word '56' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,168 : WARNING : duplicate word '179' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,168 : WARNING : duplicate word '579' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,169 : WARNING : duplicate word '829' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,170 : WARNING : duplicate word '545' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,170 : WARNING : duplicate word '283' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,171 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,171 : WARNING : duplicate word '601' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,172 : WARNING : duplicate word '942' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,174 : WARNING : duplicate word '908' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,175 : WARNING : duplicate word '409' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,176 : WARNING : duplicate word '9222' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,177 : WARNING : duplicate word '451' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,177 : WARNING : duplicate word '122' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,179 : WARNING : duplicate word '889' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,180 : WARNING : duplicate word '828' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,181 : WARNING : duplicate word '3133' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,184 : WARNING : duplicate word '805' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,185 : WARNING : duplicate word '027' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,187 : WARNING : duplicate word '679' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,190 : WARNING : duplicate word '762' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,191 : WARNING : duplicate word '05' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,192 : WARNING : duplicate word '477' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,193 : WARNING : duplicate word '38' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,195 : WARNING : duplicate word '309' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,196 : WARNING : duplicate word '884' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,196 : WARNING : duplicate word '801' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,197 : WARNING : duplicate word '068' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,198 : WARNING : duplicate word '491' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,199 : WARNING : duplicate word '8161' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,199 : WARNING : duplicate word '284' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,200 : WARNING : duplicate word '704' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,201 : WARNING : duplicate word '955' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,202 : WARNING : duplicate word '003' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,204 : WARNING : duplicate word '632' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,205 : WARNING : duplicate word '19' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,205 : WARNING : duplicate word '193' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,207 : WARNING : duplicate word '615' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,208 : WARNING : duplicate word '058' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,209 : WARNING : duplicate word '929' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,210 : WARNING : duplicate word '472' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,211 : WARNING : duplicate word '736' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,213 : WARNING : duplicate word '0661' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,214 : WARNING : duplicate word '243' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:30:31,216 : WARNING : duplicate word '1259' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,218 : WARNING : duplicate word '7928' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,219 : WARNING : duplicate word '55' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,220 : WARNING : duplicate word '303' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,220 : WARNING : duplicate word '286' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,221 : WARNING : duplicate word '717' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,222 : WARNING : duplicate word '0185' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,223 : WARNING : duplicate word '3924' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,226 : WARNING : duplicate word '5604' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,227 : WARNING : duplicate word '3952' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,228 : WARNING : duplicate word '581' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,229 : WARNING : duplicate word '2966' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,229 : WARNING : duplicate word '038' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,230 : WARNING : duplicate word '547' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,231 : WARNING : duplicate word '3588' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,232 : WARNING : duplicate word '5083' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,233 : WARNING : duplicate word '464' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,233 : WARNING : duplicate word '2045' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,234 : WARNING : duplicate word '7428' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,235 : WARNING : duplicate word '7338' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,235 : WARNING : duplicate word '1655' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,236 : WARNING : duplicate word '128' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,237 : WARNING : duplicate word '308' in dataset/twitter/word2vec.model, ignoring all but first\n",
      "2019-03-30 22:30:31,237 : WARNING : duplicate word '8283' in dataset/twitter/word2vec.model, ignoring all but first\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-93cdd04aec44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load vectors directly from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/twitter/word2vec.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#model = Word2Vec.load_word2vec_format('dataset/twitter/word2vec.model')#, binary=True, norm_only=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1435\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36madd_word\u001b[0;34m(word, weights)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mword_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"duplicate word '%s' in %s, ignoring all but first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36mwarning\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \"\"\"\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36m_log\u001b[0;34m(self, level, msg, args, exc_info, extra, stack_info)\u001b[0m\n\u001b[1;32m   1441\u001b[0m         record = self.makeRecord(self.name, level, fn, lno, msg, args,\n\u001b[1;32m   1442\u001b[0m                                  exc_info, func, extra, sinfo)\n\u001b[0;32m-> 1443\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \"\"\"\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallHandlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36mcallHandlers\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1513\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevelno\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m                     \u001b[0mhdlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m    \u001b[0;31m#break out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandleError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load vectors directly from the file\n",
    "model = KeyedVectors.load_word2vec_format('dataset/twitter/word2vec.model', binary=True)\n",
    "#model = Word2Vec.load_word2vec_format('dataset/twitter/word2vec.model')#, binary=True, norm_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:48:56,982 : INFO : loading projection weights from /home/dan/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n",
      "2019-03-30 22:49:41,011 : INFO : loaded (400000, 100) matrix from /home/dan/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 44.53785800933838 seconds to load\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"took {} seconds to load\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:48:30,620 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('slut', 0.540489673614502),\n",
       " ('fucking', 0.5119315981864929),\n",
       " ('bastard', 0.5105565190315247),\n",
       " ('whore', 0.5101016759872437),\n",
       " ('mommy', 0.4893025755882263),\n",
       " ('daddy', 0.47546058893203735),\n",
       " ('fuck', 0.46024876832962036),\n",
       " ('shit', 0.4565410614013672),\n",
       " ('ass', 0.45218026638031006),\n",
       " ('hey', 0.4478936195373535)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"bitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:43:16,824 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bastard', 0.682975172996521),\n",
       " ('whore', 0.6757593750953674),\n",
       " ('dude', 0.648766040802002),\n",
       " ('daddy', 0.6471452713012695),\n",
       " ('pimp', 0.6154674291610718),\n",
       " ('fucking', 0.6134645938873291),\n",
       " ('cunt', 0.6033082604408264),\n",
       " ('mommy', 0.6010405421257019),\n",
       " ('hell', 0.5891916751861572),\n",
       " ('ass', 0.5852797627449036)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"bitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.588909387588501"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distance(\"green\", \"color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 22:09:45,647 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ass', 0.8750526905059814),\n",
       " ('nigga', 0.8741750121116638),\n",
       " ('fuck', 0.8737877011299133),\n",
       " ('shit', 0.8599744439125061),\n",
       " ('bitches', 0.856833815574646),\n",
       " ('hoe', 0.8425132036209106),\n",
       " ('hell', 0.820566713809967),\n",
       " ('dick', 0.8192201852798462),\n",
       " ('damn', 0.811225414276123),\n",
       " ('lmao', 0.8106886148452759)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"bitch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
